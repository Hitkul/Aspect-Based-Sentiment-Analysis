{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from pickle import dump,load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import shuffle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_file_to_df(filename):\n",
    "    df = pd.read_csv(filename,delimiter='\\t',header=0)\n",
    "    df = df.drop(['Unnamed: 0', 'id'],axis=1)\n",
    "    df_text = df.iloc[:,:1]\n",
    "    df_score = df.iloc[:,1:]\n",
    "    return df_text,df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_text,headlines_score = load_file_to_df(\"FiQA_train_ABSA_financial_headlines.tsv\")\n",
    "post_text,post_score = load_file_to_df(\"FiQA_train_ABSA_financial_posts.tsv\")\n",
    "text = pd.concat([headlines_text,post_text])\n",
    "score = pd.concat([headlines_score,post_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn a sentence into clean tokens\n",
    "def clean_sentence(sentence):\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "sentences = [clean_sentence(x) for x in text['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting real number scores to lables\n",
    "#0-->-ve sentiment 1-->+ve sentiment\n",
    "labels_df = (score>=0).astype(int)\n",
    "labels = [int(x) for x in labels_df['sentiment score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1737,\n",
       " 1914,\n",
       " 3753,\n",
       " 6,\n",
       " 1582,\n",
       " 3772,\n",
       " 1526,\n",
       " 2202,\n",
       " 1071,\n",
       " 1496,\n",
       " 1420,\n",
       " 1906,\n",
       " 2510,\n",
       " 3754,\n",
       " 3216,\n",
       " 163,\n",
       " 602,\n",
       " 241,\n",
       " 1726,\n",
       " 1089,\n",
       " 3439,\n",
       " 1320,\n",
       " 640,\n",
       " 3615,\n",
       " 1715,\n",
       " 2516,\n",
       " 2998,\n",
       " 3402,\n",
       " 2305,\n",
       " 1652,\n",
       " 461,\n",
       " 1803,\n",
       " 929,\n",
       " 644,\n",
       " 1221,\n",
       " 3519,\n",
       " 2770,\n",
       " 3769,\n",
       " 2145,\n",
       " 1712,\n",
       " 67,\n",
       " 1308,\n",
       " 9,\n",
       " 2267,\n",
       " 201,\n",
       " 1372,\n",
       " 3376,\n",
       " 1339,\n",
       " 1907,\n",
       " 3283,\n",
       " 1875,\n",
       " 146,\n",
       " 2346,\n",
       " 1003,\n",
       " 338,\n",
       " 276,\n",
       " 2259,\n",
       " 1517,\n",
       " 3094,\n",
       " 3023,\n",
       " 1120,\n",
       " 686,\n",
       " 209,\n",
       " 2315,\n",
       " 3084,\n",
       " 126,\n",
       " 1391,\n",
       " 1054,\n",
       " 451,\n",
       " 3036,\n",
       " 1549,\n",
       " 3195,\n",
       " 1457,\n",
       " 907,\n",
       " 420,\n",
       " 751,\n",
       " 3478,\n",
       " 25,\n",
       " 1254,\n",
       " 2691,\n",
       " 558,\n",
       " 1148,\n",
       " 3248,\n",
       " 961,\n",
       " 403,\n",
       " 3714,\n",
       " 3602,\n",
       " 20,\n",
       " 2920,\n",
       " 27,\n",
       " 2089,\n",
       " 1147,\n",
       " 3050,\n",
       " 3297,\n",
       " 3506,\n",
       " 394,\n",
       " 2680,\n",
       " 2352,\n",
       " 1625,\n",
       " 3320,\n",
       " 698,\n",
       " 1292,\n",
       " 93,\n",
       " 1479,\n",
       " 2805,\n",
       " 3261,\n",
       " 1346,\n",
       " 3153,\n",
       " 3617,\n",
       " 3758,\n",
       " 1442,\n",
       " 2606,\n",
       " 2207,\n",
       " 2233,\n",
       " 1508,\n",
       " 1249,\n",
       " 2037,\n",
       " 2062,\n",
       " 2301,\n",
       " 1836,\n",
       " 351,\n",
       " 2698,\n",
       " 1183,\n",
       " 2158,\n",
       " 2790,\n",
       " 2566,\n",
       " 3119,\n",
       " 1022,\n",
       " 1345,\n",
       " 3458,\n",
       " 3429,\n",
       " 2722,\n",
       " 299,\n",
       " 312,\n",
       " 3420,\n",
       " 525,\n",
       " 3649,\n",
       " 1898,\n",
       " 1150,\n",
       " 817,\n",
       " 2879,\n",
       " 3661,\n",
       " 955,\n",
       " 1102,\n",
       " 2022,\n",
       " 757,\n",
       " 1691,\n",
       " 3069,\n",
       " 1916,\n",
       " 1844,\n",
       " 1533,\n",
       " 3561,\n",
       " 2709,\n",
       " 2470,\n",
       " 3152,\n",
       " 1332,\n",
       " 464,\n",
       " 1797,\n",
       " 1485,\n",
       " 3693,\n",
       " 1406,\n",
       " 3743,\n",
       " 1678,\n",
       " 2452,\n",
       " 397,\n",
       " 1444,\n",
       " 1112,\n",
       " 943,\n",
       " 1431,\n",
       " 1744,\n",
       " 387,\n",
       " 102,\n",
       " 3612,\n",
       " 2569,\n",
       " 2561,\n",
       " 54,\n",
       " 798,\n",
       " 901,\n",
       " 1628,\n",
       " 2387,\n",
       " 860,\n",
       " 730,\n",
       " 1367,\n",
       " 2831,\n",
       " 877,\n",
       " 3415,\n",
       " 3085,\n",
       " 3516,\n",
       " 171,\n",
       " 2812,\n",
       " 490,\n",
       " 1482,\n",
       " 2195,\n",
       " 709,\n",
       " 2299,\n",
       " 409,\n",
       " 2707,\n",
       " 1640,\n",
       " 78,\n",
       " 1766,\n",
       " 2890,\n",
       " 2185,\n",
       " 247,\n",
       " 3083,\n",
       " 314,\n",
       " 322,\n",
       " 628,\n",
       " 344,\n",
       " 411,\n",
       " 3221,\n",
       " 3560,\n",
       " 2140,\n",
       " 2388,\n",
       " 2072,\n",
       " 3123,\n",
       " 2675,\n",
       " 3159,\n",
       " 625,\n",
       " 2104,\n",
       " 3263,\n",
       " 1435,\n",
       " 2318,\n",
       " 1815,\n",
       " 3781,\n",
       " 3113,\n",
       " 2049,\n",
       " 2353,\n",
       " 3223,\n",
       " 3183,\n",
       " 3056,\n",
       " 3111,\n",
       " 2965,\n",
       " 2993,\n",
       " 2840,\n",
       " 2931,\n",
       " 920,\n",
       " 286,\n",
       " 3652,\n",
       " 2714,\n",
       " 3450,\n",
       " 1009,\n",
       " 3740,\n",
       " 2188,\n",
       " 1121,\n",
       " 842,\n",
       " 3373,\n",
       " 950,\n",
       " 443,\n",
       " 3080,\n",
       " 3434,\n",
       " 885,\n",
       " 2661,\n",
       " 1331,\n",
       " 1351,\n",
       " 315,\n",
       " 3676,\n",
       " 2501,\n",
       " 2415,\n",
       " 1299,\n",
       " 142,\n",
       " 2092,\n",
       " 2330,\n",
       " 1969,\n",
       " 1647,\n",
       " 2306,\n",
       " 2858,\n",
       " 2286,\n",
       " 3117,\n",
       " 1070,\n",
       " 768,\n",
       " 3057,\n",
       " 1968,\n",
       " 2440,\n",
       " 226,\n",
       " 3713,\n",
       " 1226,\n",
       " 2447,\n",
       " 1576,\n",
       " 1343,\n",
       " 1786,\n",
       " 1524,\n",
       " 392,\n",
       " 2320,\n",
       " 572,\n",
       " 3194,\n",
       " 2482,\n",
       " 424,\n",
       " 3131,\n",
       " 1644,\n",
       " 3238,\n",
       " 1656,\n",
       " 7,\n",
       " 1045,\n",
       " 2947,\n",
       " 2717,\n",
       " 1585,\n",
       " 3001,\n",
       " 745,\n",
       " 3671,\n",
       " 1443,\n",
       " 882,\n",
       " 1518,\n",
       " 3552,\n",
       " 3526,\n",
       " 1276,\n",
       " 2385,\n",
       " 482,\n",
       " 3727,\n",
       " 2479,\n",
       " 3156,\n",
       " 3501,\n",
       " 690,\n",
       " 1516,\n",
       " 1554,\n",
       " 109,\n",
       " 666,\n",
       " 1187,\n",
       " 1862,\n",
       " 2449,\n",
       " 2787,\n",
       " 3547,\n",
       " 1202,\n",
       " 3741,\n",
       " 867,\n",
       " 3127,\n",
       " 285,\n",
       " 608,\n",
       " 3684,\n",
       " 454,\n",
       " 3019,\n",
       " 1951,\n",
       " 890,\n",
       " 1874,\n",
       " 1092,\n",
       " 1781,\n",
       " 2843,\n",
       " 1337,\n",
       " 3583,\n",
       " 1954,\n",
       " 3647,\n",
       " 1899,\n",
       " 3150,\n",
       " 1804,\n",
       " 2199,\n",
       " 1509,\n",
       " 1236,\n",
       " 1895,\n",
       " 2649,\n",
       " 2523,\n",
       " 3533,\n",
       " 2628,\n",
       " 495,\n",
       " 3765,\n",
       " 1464,\n",
       " 2403,\n",
       " 2776,\n",
       " 3658,\n",
       " 3573,\n",
       " 996,\n",
       " 12,\n",
       " 2,\n",
       " 455,\n",
       " 1795,\n",
       " 3093,\n",
       " 2653,\n",
       " 61,\n",
       " 3214,\n",
       " 3614,\n",
       " 309,\n",
       " 2068,\n",
       " 58,\n",
       " 1768,\n",
       " 2309,\n",
       " 3331,\n",
       " 1033,\n",
       " 3624,\n",
       " 1771,\n",
       " 2551,\n",
       " 292,\n",
       " 3185,\n",
       " 2917,\n",
       " 3060,\n",
       " 518,\n",
       " 816,\n",
       " 3636,\n",
       " 840,\n",
       " 2018,\n",
       " 3593,\n",
       " 3596,\n",
       " 2671,\n",
       " 203,\n",
       " 2950,\n",
       " 2774,\n",
       " 2962,\n",
       " 3174,\n",
       " 3228,\n",
       " 1025,\n",
       " 1562,\n",
       " 3469,\n",
       " 2121,\n",
       " 2655,\n",
       " 2648,\n",
       " 398,\n",
       " 233,\n",
       " 2690,\n",
       " 2409,\n",
       " 2815,\n",
       " 3325,\n",
       " 1970,\n",
       " 3459,\n",
       " 494,\n",
       " 2128,\n",
       " 2522,\n",
       " 3089,\n",
       " 2940,\n",
       " 1208,\n",
       " 157,\n",
       " 1082,\n",
       " 3535,\n",
       " 1473,\n",
       " 3357,\n",
       " 2821,\n",
       " 1018,\n",
       " 243,\n",
       " 2633,\n",
       " 3004,\n",
       " 1206,\n",
       " 3279,\n",
       " 3385,\n",
       " 1144,\n",
       " 1681,\n",
       " 825,\n",
       " 3038,\n",
       " 2623,\n",
       " 1301,\n",
       " 2220,\n",
       " 3431,\n",
       " 1461,\n",
       " 1067,\n",
       " 2966,\n",
       " 2754,\n",
       " 834,\n",
       " 2792,\n",
       " 1177,\n",
       " 467,\n",
       " 1915,\n",
       " 578,\n",
       " 1135,\n",
       " 2929,\n",
       " 2132,\n",
       " 660,\n",
       " 1245,\n",
       " 1416,\n",
       " 1913,\n",
       " 552,\n",
       " 1334,\n",
       " 2472,\n",
       " 584,\n",
       " 38,\n",
       " 2785,\n",
       " 3768,\n",
       " 196,\n",
       " 498,\n",
       " 891,\n",
       " 3773,\n",
       " 1041,\n",
       " 3440,\n",
       " 418,\n",
       " 2603,\n",
       " 3640,\n",
       " 1717,\n",
       " 1140,\n",
       " 427,\n",
       " 923,\n",
       " 3292,\n",
       " 2545,\n",
       " 1451,\n",
       " 1575,\n",
       " 1579,\n",
       " 3257,\n",
       " 1109,\n",
       " 2490,\n",
       " 433,\n",
       " 477,\n",
       " 801,\n",
       " 1822,\n",
       " 3157,\n",
       " 2954,\n",
       " 2304,\n",
       " 3186,\n",
       " 992,\n",
       " 1094,\n",
       " 1679,\n",
       " 77,\n",
       " 2868,\n",
       " 2978,\n",
       " 1992,\n",
       " 1881,\n",
       " 2585,\n",
       " 2102,\n",
       " 2753,\n",
       " 2074,\n",
       " 471,\n",
       " 2732,\n",
       " 2244,\n",
       " 134,\n",
       " 1352,\n",
       " 3686,\n",
       " 1674,\n",
       " 916,\n",
       " 293,\n",
       " 3193,\n",
       " 1220,\n",
       " 2462,\n",
       " 2156,\n",
       " 2530,\n",
       " 1412,\n",
       " 296,\n",
       " 235,\n",
       " 1488,\n",
       " 2177,\n",
       " 1590,\n",
       " 648,\n",
       " 305,\n",
       " 1542,\n",
       " 1445,\n",
       " 2874,\n",
       " 1012,\n",
       " 1048,\n",
       " 3488,\n",
       " 981,\n",
       " 3423,\n",
       " 2855,\n",
       " 818,\n",
       " 1174,\n",
       " 2319,\n",
       " 3637,\n",
       " 3589,\n",
       " 1900,\n",
       " 2173,\n",
       " 1578,\n",
       " 684,\n",
       " 3433,\n",
       " 3639,\n",
       " 3690,\n",
       " 1438,\n",
       " 2961,\n",
       " 13,\n",
       " 2229,\n",
       " 320,\n",
       " 1218,\n",
       " 1242,\n",
       " 311,\n",
       " 1123,\n",
       " 3502,\n",
       " 1434,\n",
       " 373,\n",
       " 878,\n",
       " 700,\n",
       " 1767,\n",
       " 225,\n",
       " 3143,\n",
       " 3026,\n",
       " 813,\n",
       " 1779,\n",
       " 3670,\n",
       " 2031,\n",
       " 3147,\n",
       " 3040,\n",
       " 595,\n",
       " 1043,\n",
       " 2631,\n",
       " 2896,\n",
       " 2398,\n",
       " 1802,\n",
       " 2937,\n",
       " 3559,\n",
       " 2141,\n",
       " 2535,\n",
       " 909,\n",
       " 1617,\n",
       " 1967,\n",
       " 1632,\n",
       " 1360,\n",
       " 688,\n",
       " 3231,\n",
       " 1338,\n",
       " 3148,\n",
       " 1415,\n",
       " 2905,\n",
       " 1745,\n",
       " 1825,\n",
       " 283,\n",
       " 3259,\n",
       " 1758,\n",
       " 1600,\n",
       " 3608,\n",
       " 3634,\n",
       " 3391,\n",
       " 2942,\n",
       " 3030,\n",
       " 1069,\n",
       " 732,\n",
       " 2936,\n",
       " 2044,\n",
       " 2687,\n",
       " 1204,\n",
       " 2137,\n",
       " 438,\n",
       " 3000,\n",
       " 3260,\n",
       " 975,\n",
       " 3667,\n",
       " 3087,\n",
       " 3520,\n",
       " 1688,\n",
       " 230,\n",
       " 2826,\n",
       " 1756,\n",
       " 2295,\n",
       " 603,\n",
       " 1821,\n",
       " 1684,\n",
       " 2221,\n",
       " 3453,\n",
       " 1888,\n",
       " 2521,\n",
       " 2681,\n",
       " 618,\n",
       " 3668,\n",
       " 1176,\n",
       " 2342,\n",
       " 1762,\n",
       " 585,\n",
       " 487,\n",
       " 3348,\n",
       " 1439,\n",
       " 2559,\n",
       " 2607,\n",
       " 2778,\n",
       " 1563,\n",
       " 2970,\n",
       " 1028,\n",
       " 1134,\n",
       " 537,\n",
       " 1974,\n",
       " 1602,\n",
       " 849,\n",
       " 3009,\n",
       " 764,\n",
       " 2094,\n",
       " 2354,\n",
       " 139,\n",
       " 1361,\n",
       " 3586,\n",
       " 2811,\n",
       " 3121,\n",
       " 1851,\n",
       " 2828,\n",
       " 1411,\n",
       " 2251,\n",
       " 3064,\n",
       " 1943,\n",
       " 2515,\n",
       " 3737,\n",
       " 1231,\n",
       " 3303,\n",
       " 3718,\n",
       " 1636,\n",
       " 119,\n",
       " 2036,\n",
       " 1960,\n",
       " 1634,\n",
       " 3317,\n",
       " 1637,\n",
       " 2640,\n",
       " 3286,\n",
       " 2932,\n",
       " 385,\n",
       " 1259,\n",
       " 2038,\n",
       " 1199,\n",
       " 1167,\n",
       " 922,\n",
       " 662,\n",
       " 2024,\n",
       " 2512,\n",
       " 1646,\n",
       " 581,\n",
       " 1677,\n",
       " 2183,\n",
       " 125,\n",
       " 526,\n",
       " 80,\n",
       " 1650,\n",
       " 2013,\n",
       " 1362,\n",
       " 2050,\n",
       " 3403,\n",
       " 3659,\n",
       " 1868,\n",
       " 1800,\n",
       " 3446,\n",
       " 2741,\n",
       " 2395,\n",
       " 919,\n",
       " 3413,\n",
       " 79,\n",
       " 665,\n",
       " 1329,\n",
       " 2380,\n",
       " 504,\n",
       " 755,\n",
       " 2135,\n",
       " 597,\n",
       " 2256,\n",
       " 1175,\n",
       " 3244,\n",
       " 14,\n",
       " 414,\n",
       " 460,\n",
       " 1381,\n",
       " 1525,\n",
       " 2883,\n",
       " 1559,\n",
       " 752,\n",
       " 3041,\n",
       " 1714,\n",
       " 2706,\n",
       " 1764,\n",
       " 2730,\n",
       " 207,\n",
       " 2281,\n",
       " 3435,\n",
       " 590,\n",
       " 697,\n",
       " 3746,\n",
       " 2057,\n",
       " 2328,\n",
       " 3284,\n",
       " 1956,\n",
       " 637,\n",
       " 663,\n",
       " 1313,\n",
       " 1244,\n",
       " 376,\n",
       " 218,\n",
       " 3539,\n",
       " 63,\n",
       " 2646,\n",
       " 3246,\n",
       " 1826,\n",
       " 465,\n",
       " 2168,\n",
       " 1989,\n",
       " 2862,\n",
       " 2136,\n",
       " 72,\n",
       " 1839,\n",
       " 3226,\n",
       " 2735,\n",
       " 1072,\n",
       " 152,\n",
       " 3393,\n",
       " 2429,\n",
       " 2842,\n",
       " 1460,\n",
       " 2780,\n",
       " 1734,\n",
       " 1038,\n",
       " 49,\n",
       " 288,\n",
       " 3354,\n",
       " 1896,\n",
       " 3330,\n",
       " 1118,\n",
       " 1193,\n",
       " 2166,\n",
       " 2406,\n",
       " 2782,\n",
       " 3105,\n",
       " 1642,\n",
       " 1565,\n",
       " 2100,\n",
       " 3490,\n",
       " 3721,\n",
       " 2274,\n",
       " 3162,\n",
       " 1841,\n",
       " 261,\n",
       " 1606,\n",
       " 15,\n",
       " 3572,\n",
       " 710,\n",
       " 3198,\n",
       " 2969,\n",
       " 2324,\n",
       " 3275,\n",
       " 2804,\n",
       " 2303,\n",
       " 2326,\n",
       " 2494,\n",
       " 3209,\n",
       " 19,\n",
       " 1157,\n",
       " 717,\n",
       " 2540,\n",
       " 2466,\n",
       " 2654,\n",
       " 2249,\n",
       " 2344,\n",
       " 3167,\n",
       " 3471,\n",
       " 2481,\n",
       " 2340,\n",
       " 2203,\n",
       " 3486,\n",
       " 701,\n",
       " 319,\n",
       " 2053,\n",
       " 3770,\n",
       " 706,\n",
       " 405,\n",
       " 1621,\n",
       " 761,\n",
       " 1556,\n",
       " 348,\n",
       " 620,\n",
       " 3585,\n",
       " 2930,\n",
       " 475,\n",
       " 2613,\n",
       " 1392,\n",
       " 3091,\n",
       " 2875,\n",
       " 2357,\n",
       " 1979,\n",
       " 3545,\n",
       " 3494,\n",
       " 3430,\n",
       " 1902,\n",
       " 2410,\n",
       " 3683,\n",
       " 3551,\n",
       " 1201,\n",
       " 2210,\n",
       " 2017,\n",
       " 1459,\n",
       " 2035,\n",
       " 2317,\n",
       " 807,\n",
       " 2111,\n",
       " 2381,\n",
       " 52,\n",
       " 2731,\n",
       " 136,\n",
       " 1214,\n",
       " 1552,\n",
       " 3075,\n",
       " 259,\n",
       " 1682,\n",
       " 2030,\n",
       " 1723,\n",
       " 2492,\n",
       " 2097,\n",
       " 390,\n",
       " 2455,\n",
       " 2664,\n",
       " 1449,\n",
       " 3222,\n",
       " 741,\n",
       " 506,\n",
       " 2822,\n",
       " 2020,\n",
       " 216,\n",
       " 2503,\n",
       " 193,\n",
       " 2288,\n",
       " 1474,\n",
       " 553,\n",
       " 1369,\n",
       " 2067,\n",
       " 624,\n",
       " 1583,\n",
       " 2856,\n",
       " 2427,\n",
       " 3066,\n",
       " 681,\n",
       " 1400,\n",
       " 220,\n",
       " 2742,\n",
       " 3760,\n",
       " 3142,\n",
       " 303,\n",
       " 881,\n",
       " 3024,\n",
       " 3592,\n",
       " 1483,\n",
       " 1539,\n",
       " 3289,\n",
       " 101,\n",
       " 2844,\n",
       " 3171,\n",
       " 2657,\n",
       " 1318,\n",
       " 594,\n",
       " 844,\n",
       " 3033,\n",
       " 191,\n",
       " 1256,\n",
       " 2703,\n",
       " 2351,\n",
       " 3364,\n",
       " 522,\n",
       " 1419,\n",
       " 570,\n",
       " 1105,\n",
       " 2358,\n",
       " 3625,\n",
       " 2444,\n",
       " 3568,\n",
       " 2853,\n",
       " 762,\n",
       " 2000,\n",
       " 1316,\n",
       " 56,\n",
       " 560,\n",
       " 62,\n",
       " 999,\n",
       " 484,\n",
       " 374,\n",
       " 2999,\n",
       " 2593,\n",
       " 1324,\n",
       " 804,\n",
       " 1503,\n",
       " 799,\n",
       " 1487,\n",
       " 100,\n",
       " 2546,\n",
       " 1639,\n",
       " 691,\n",
       " 1718,\n",
       " 1246,\n",
       " 2441,\n",
       " 1694,\n",
       " 1608,\n",
       " 2701,\n",
       " 2193,\n",
       " 2621,\n",
       " 2231,\n",
       " 3460,\n",
       " 1210,\n",
       " 2622,\n",
       " 567,\n",
       " 1064,\n",
       " 841,\n",
       " 880,\n",
       " 2695,\n",
       " 1858,\n",
       " 748,\n",
       " 2277,\n",
       " 1267,\n",
       " 1735,\n",
       " 3200,\n",
       " 1649,\n",
       " 166,\n",
       " 1864,\n",
       " 2171,\n",
       " 1746,\n",
       " 2697,\n",
       " 3090,\n",
       " 2051,\n",
       " 779,\n",
       " 3733,\n",
       " 2705,\n",
       " 1154,\n",
       " 2948,\n",
       " 1696,\n",
       " 3241,\n",
       " 2668,\n",
       " 931,\n",
       " 3215,\n",
       " 507,\n",
       " 1846,\n",
       " 1880,\n",
       " 557,\n",
       " 1513,\n",
       " 599,\n",
       " 2517,\n",
       " 1995,\n",
       " 563,\n",
       " 833,\n",
       " 2590,\n",
       " 2608,\n",
       " 574,\n",
       " 3752,\n",
       " 658,\n",
       " 11,\n",
       " 3164,\n",
       " ...]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffling dataset\n",
    "numbers = [i for i in range(len(sentences))]\n",
    "shuffle(numbers)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3789\n",
      "3789\n"
     ]
    }
   ],
   "source": [
    "temp_text = sentences\n",
    "temp_lables = labels\n",
    "for i in numbers:\n",
    "    sentences[i] = temp_text[i]\n",
    "    labels[i]=temp_lables[i]\n",
    "print(len(sentences))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#doing train and test split\n",
    "test_train_split_ratio =0.9\n",
    "trainX,testX = sentences[:int(test_train_split_ratio*len(sentences))],sentences[int(test_train_split_ratio*len(sentences)):]\n",
    "trainY,testY = labels[:int(test_train_split_ratio*len(labels))],labels[int(test_train_split_ratio*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410 3410\n",
      "379 379\n"
     ]
    }
   ],
   "source": [
    "print(len(trainX),len(trainY))\n",
    "print(len(testX),len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the maximum document length\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testLines = [' '.join(x) for x in testX]\n",
    "trainLines = [' '.join(x) for x in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainY = np.array(trainY)\n",
    "# testY = np.array(testY)\n",
    "# type(trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 23\n",
      "Vocabulary size: 6884\n",
      "(3410, 23)\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = create_tokenizer(trainLines)\n",
    "# calculate max document length\n",
    "length = max_length(trainLines)\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % length)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "# encode data\n",
    "trainX = encode_text(tokenizer, trainLines, length)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_46 (InputLayer)           (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 23, 100)      688400      input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 23, 100)      688400      input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 23, 100)      688400      input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 20, 32)       12832       embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 18, 32)       19232       embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 16, 32)       25632       embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 20, 32)       0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 18, 32)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 32)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 10, 32)       0           dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 9, 32)        0           dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 8, 32)        0           dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 320)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 288)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 256)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 864)          0           flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 10)           8650        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1)            11          dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,131,557\n",
      "Trainable params: 2,131,557\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = define_model(length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit([trainX,trainX,trainX], trainY, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3410, 23) (379, 23)\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "# encode data\n",
    "# trainX = encode_text(tokenizer, trainLines, length)\n",
    "testX = encode_text(tokenizer, testLines, length)\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.299120\n",
      "Test Accuracy: 82.058048\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset\n",
    "loss, acc = model.evaluate([trainX,trainX,trainX], trainY, verbose=0)\n",
    "print('Train Accuracy: %f' % (acc*100))\n",
    " \n",
    "# evaluate model on test dataset dataset\n",
    "loss, acc = model.evaluate([testX,testX,testX], testY, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9917216897010803,\n",
       " 0.5519030094146729,\n",
       " 0.3393690884113312,\n",
       " 0.019103292375802994,\n",
       " 0.0006588365067727864,\n",
       " 0.06140361353754997,\n",
       " 0.9871463775634766,\n",
       " 0.997307538986206,\n",
       " 0.39849168062210083,\n",
       " 0.9229839444160461,\n",
       " 0.9906712770462036,\n",
       " 0.9992703795433044,\n",
       " 0.056199293583631516,\n",
       " 0.9547330141067505,\n",
       " 0.45457160472869873,\n",
       " 0.5067245364189148,\n",
       " 0.8612037897109985,\n",
       " 0.9984258413314819,\n",
       " 0.9950929880142212,\n",
       " 0.9991890788078308,\n",
       " 0.9369710087776184,\n",
       " 0.7053764462471008,\n",
       " 0.8962070941925049,\n",
       " 0.5635888576507568,\n",
       " 0.21669049561023712,\n",
       " 0.5777891278266907,\n",
       " 0.41223880648612976,\n",
       " 0.9966940879821777,\n",
       " 0.9961928129196167,\n",
       " 0.45327073335647583,\n",
       " 0.6472412943840027,\n",
       " 0.4583706259727478,\n",
       " 0.9508475065231323,\n",
       " 0.9027577042579651,\n",
       " 0.10071637481451035,\n",
       " 0.8224546313285828,\n",
       " 0.04126504436135292,\n",
       " 0.0010255440138280392,\n",
       " 0.9911794066429138,\n",
       " 0.5619944334030151,\n",
       " 0.582688570022583,\n",
       " 0.7861183881759644,\n",
       " 0.591829776763916,\n",
       " 0.5150099396705627,\n",
       " 0.9491631388664246,\n",
       " 0.7904559373855591,\n",
       " 0.9967382550239563,\n",
       " 0.9410573840141296,\n",
       " 0.31556904315948486,\n",
       " 0.0005224914057180285,\n",
       " 0.020944392308592796,\n",
       " 0.40471237897872925,\n",
       " 0.16178357601165771,\n",
       " 0.3845771849155426,\n",
       " 0.9715836048126221,\n",
       " 0.8852350115776062,\n",
       " 0.992060661315918,\n",
       " 0.9994563460350037,\n",
       " 0.9972731471061707,\n",
       " 0.893376886844635,\n",
       " 0.6387795805931091,\n",
       " 0.31036385893821716,\n",
       " 0.9920822381973267,\n",
       " 0.5670316815376282,\n",
       " 0.9878705143928528,\n",
       " 0.0004407308006193489,\n",
       " 0.036598414182662964,\n",
       " 0.48769649863243103,\n",
       " 0.0020389403216540813,\n",
       " 0.0004801789182238281,\n",
       " 0.002414781367406249,\n",
       " 0.0005224914057180285,\n",
       " 0.9949323534965515,\n",
       " 0.9966710209846497,\n",
       " 0.926072895526886,\n",
       " 0.999496340751648,\n",
       " 0.999798595905304,\n",
       " 0.0004801789182238281,\n",
       " 0.9984258413314819,\n",
       " 0.6309190988540649,\n",
       " 0.9957945346832275,\n",
       " 0.039315707981586456,\n",
       " 0.886265754699707,\n",
       " 0.1800234168767929,\n",
       " 0.9858075380325317,\n",
       " 0.9846649765968323,\n",
       " 7.463368820026517e-05,\n",
       " 0.03521721065044403,\n",
       " 0.8415976762771606,\n",
       " 0.019275572150945663,\n",
       " 0.25112059712409973,\n",
       " 0.963124692440033,\n",
       " 0.4467078149318695,\n",
       " 0.0004954244941473007,\n",
       " 0.9994088411331177,\n",
       " 0.13841214776039124,\n",
       " 0.0011886490974575281,\n",
       " 0.9892435073852539,\n",
       " 0.9892435073852539,\n",
       " 0.9966148734092712,\n",
       " 0.9997147917747498,\n",
       " 0.9997147917747498,\n",
       " 0.9955950379371643,\n",
       " 0.972537100315094,\n",
       " 0.0003821556456387043,\n",
       " 0.0004801789182238281,\n",
       " 0.9218930602073669,\n",
       " 0.33744969964027405,\n",
       " 0.5068691372871399,\n",
       " 0.4560019373893738,\n",
       " 0.5139289498329163,\n",
       " 0.0004801789182238281,\n",
       " 0.9995844960212708,\n",
       " 0.0014278737362474203,\n",
       " 0.998874843120575,\n",
       " 0.9449838995933533,\n",
       " 0.9995642304420471,\n",
       " 0.9995642304420471,\n",
       " 0.9952080845832825,\n",
       " 0.40386271476745605,\n",
       " 0.9997147917747498,\n",
       " 0.9991890788078308,\n",
       " 0.0012286355486139655,\n",
       " 0.9994563460350037,\n",
       " 0.9998125433921814,\n",
       " 0.9998125433921814,\n",
       " 0.9925633072853088,\n",
       " 0.0017825323157012463,\n",
       " 0.0018523751059547067,\n",
       " 0.9987843632698059,\n",
       " 0.0009762038243934512,\n",
       " 0.8806665539741516,\n",
       " 0.9409031867980957,\n",
       " 0.837300717830658,\n",
       " 0.6713119745254517,\n",
       " 0.9839173555374146,\n",
       " 0.9966710209846497,\n",
       " 0.99400395154953,\n",
       " 0.98149174451828,\n",
       " 0.9297250509262085,\n",
       " 0.9902551770210266,\n",
       " 0.8530162572860718,\n",
       " 0.9980890154838562,\n",
       " 0.975899338722229,\n",
       " 0.9987911581993103,\n",
       " 0.9744972586631775,\n",
       " 7.463368820026517e-05,\n",
       " 0.0665486603975296,\n",
       " 0.991986870765686,\n",
       " 0.0009368096943944693,\n",
       " 0.0003437178675085306,\n",
       " 0.9991342425346375,\n",
       " 0.399566650390625,\n",
       " 0.9965245127677917,\n",
       " 0.0009368096943944693,\n",
       " 0.6446924805641174,\n",
       " 0.9969809651374817,\n",
       " 0.9984258413314819,\n",
       " 0.9997839331626892,\n",
       " 0.47766339778900146,\n",
       " 0.5619874596595764,\n",
       " 0.001259949174709618,\n",
       " 0.5456364154815674,\n",
       " 0.08486026525497437,\n",
       " 0.5619874596595764,\n",
       " 0.9308921694755554,\n",
       " 0.56171715259552,\n",
       " 0.676621675491333,\n",
       " 0.998874843120575,\n",
       " 0.00011400948278605938,\n",
       " 0.6133169531822205,\n",
       " 0.9997147917747498,\n",
       " 7.463368820026517e-05,\n",
       " 0.9893718361854553,\n",
       " 0.0016054651932790875,\n",
       " 0.998817503452301,\n",
       " 0.9997147917747498,\n",
       " 0.9997147917747498,\n",
       " 0.999798595905304,\n",
       " 0.9903906583786011,\n",
       " 0.9560520052909851,\n",
       " 0.3876507878303528,\n",
       " 0.9969809651374817,\n",
       " 0.0005224914057180285,\n",
       " 0.2895270884037018,\n",
       " 0.0004954244941473007,\n",
       " 0.998817503452301,\n",
       " 0.9949249029159546,\n",
       " 0.589262068271637,\n",
       " 0.9995642304420471,\n",
       " 0.9991890788078308,\n",
       " 0.9995642304420471,\n",
       " 0.9973249435424805,\n",
       " 0.8663942813873291,\n",
       " 0.9905915856361389,\n",
       " 0.0004954244941473007,\n",
       " 0.0035515993367880583,\n",
       " 7.463368820026517e-05,\n",
       " 0.0004801789182238281,\n",
       " 0.999496340751648,\n",
       " 0.9984258413314819,\n",
       " 0.0003821556456387043,\n",
       " 0.9812657237052917,\n",
       " 0.0018523751059547067,\n",
       " 0.989798903465271,\n",
       " 0.0004801789182238281,\n",
       " 0.9988436698913574,\n",
       " 0.2216465175151825,\n",
       " 0.9788645505905151,\n",
       " 0.9988436698913574,\n",
       " 0.0041219438426196575,\n",
       " 0.0035515993367880583,\n",
       " 0.9876238107681274,\n",
       " 0.999496340751648,\n",
       " 0.995122492313385,\n",
       " 0.0018523751059547067,\n",
       " 0.003958749119192362,\n",
       " 0.0009762038243934512,\n",
       " 0.9943569302558899,\n",
       " 0.0041219438426196575,\n",
       " 0.0035515993367880583,\n",
       " 0.0009762038243934512,\n",
       " 0.0004407308006193489,\n",
       " 0.998817503452301,\n",
       " 0.9971339702606201,\n",
       " 0.9897880554199219,\n",
       " 0.9879926443099976,\n",
       " 7.463368820026517e-05,\n",
       " 0.9998125433921814,\n",
       " 7.463368820026517e-05,\n",
       " 0.00011400948278605938,\n",
       " 0.9992689490318298,\n",
       " 0.997307538986206,\n",
       " 0.35342931747436523,\n",
       " 0.9571440815925598,\n",
       " 0.02992289327085018,\n",
       " 0.9897880554199219,\n",
       " 0.9878209233283997,\n",
       " 0.9089506268501282,\n",
       " 0.9913538098335266,\n",
       " 0.9992703795433044,\n",
       " 0.5503853559494019,\n",
       " 0.9905915856361389,\n",
       " 0.8948986530303955,\n",
       " 0.9991890788078308,\n",
       " 0.9348246455192566,\n",
       " 0.9953694939613342,\n",
       " 0.8381360769271851,\n",
       " 0.9168788194656372,\n",
       " 0.7227605581283569,\n",
       " 0.5492041707038879,\n",
       " 0.11394105851650238,\n",
       " 0.1950412392616272,\n",
       " 0.31036385893821716,\n",
       " 0.9141514301300049,\n",
       " 0.0004801789182238281,\n",
       " 0.6031478643417358,\n",
       " 0.005962781608104706,\n",
       " 0.1912185251712799,\n",
       " 0.9307053089141846,\n",
       " 0.9998125433921814,\n",
       " 0.9987843632698059,\n",
       " 0.0004801789182238281,\n",
       " 0.9998125433921814,\n",
       " 0.999496340751648,\n",
       " 0.989329993724823,\n",
       " 0.9957945346832275,\n",
       " 0.1800234168767929,\n",
       " 0.9991890788078308,\n",
       " 0.963124692440033,\n",
       " 0.9953694939613342,\n",
       " 0.00011400948278605938,\n",
       " 0.9876238107681274,\n",
       " 0.0004801789182238281,\n",
       " 0.15868355333805084,\n",
       " 0.3907192647457123,\n",
       " 0.9936695694923401,\n",
       " 0.5211394429206848,\n",
       " 0.6333509087562561,\n",
       " 0.6446924805641174,\n",
       " 0.9967382550239563,\n",
       " 0.9988436698913574,\n",
       " 0.9990808963775635,\n",
       " 0.9965245127677917,\n",
       " 0.14685599505901337,\n",
       " 0.8778670430183411,\n",
       " 0.4514748752117157,\n",
       " 0.7528588175773621,\n",
       " 0.7775382399559021,\n",
       " 0.29990649223327637,\n",
       " 0.3506479859352112,\n",
       " 0.8778670430183411,\n",
       " 0.2943311631679535,\n",
       " 0.9728530049324036,\n",
       " 0.08250359445810318,\n",
       " 0.9859451651573181,\n",
       " 0.9998125433921814,\n",
       " 0.9245436191558838,\n",
       " 0.8364474773406982,\n",
       " 0.7453261613845825,\n",
       " 0.8306753039360046,\n",
       " 0.49205517768859863,\n",
       " 0.6229274868965149,\n",
       " 0.027090545743703842,\n",
       " 0.762427031993866,\n",
       " 0.9952080845832825,\n",
       " 0.03151635453104973,\n",
       " 0.044617071747779846,\n",
       " 0.997307538986206,\n",
       " 0.5338517427444458,\n",
       " 0.9850926995277405,\n",
       " 0.9846411347389221,\n",
       " 0.5550684332847595,\n",
       " 0.9992703795433044,\n",
       " 0.5749149918556213,\n",
       " 0.0034131098072975874,\n",
       " 0.0041219438426196575,\n",
       " 0.4173229932785034,\n",
       " 0.9958388805389404,\n",
       " 0.006162656936794519,\n",
       " 0.9991890788078308,\n",
       " 0.9327181577682495,\n",
       " 0.9969809651374817,\n",
       " 0.9790346622467041,\n",
       " 0.9953694939613342,\n",
       " 0.9966940879821777,\n",
       " 0.9674952030181885,\n",
       " 0.9906602501869202,\n",
       " 0.9932897686958313,\n",
       " 0.9871808886528015,\n",
       " 0.9557158946990967,\n",
       " 0.7750674486160278,\n",
       " 0.003693400416523218,\n",
       " 0.7295480966567993,\n",
       " 0.16054365038871765,\n",
       " 0.7227605581283569,\n",
       " 0.0034654417540878057,\n",
       " 0.46416643261909485,\n",
       " 0.0023700736928731203,\n",
       " 0.05224015563726425,\n",
       " 0.6297654509544373,\n",
       " 0.0010255440138280392,\n",
       " 0.9249534010887146,\n",
       " 0.6239746809005737,\n",
       " 0.5492041707038879,\n",
       " 0.9987989664077759,\n",
       " 0.9009307026863098,\n",
       " 0.7200126051902771,\n",
       " 0.38973164558410645,\n",
       " 0.0035515993367880583,\n",
       " 0.570824146270752,\n",
       " 0.9955247640609741,\n",
       " 0.9967382550239563,\n",
       " 0.9410573840141296,\n",
       " 0.5068886280059814,\n",
       " 0.9949089884757996,\n",
       " 0.16030165553092957,\n",
       " 0.4030441641807556,\n",
       " 0.992060661315918,\n",
       " 0.0009762038243934512,\n",
       " 0.9972731471061707,\n",
       " 0.9564248323440552,\n",
       " 0.31036385893821716,\n",
       " 0.32850807905197144,\n",
       " 0.7762545943260193,\n",
       " 0.9934448003768921,\n",
       " 0.5245808959007263,\n",
       " 0.9924310445785522,\n",
       " 0.5448812246322632,\n",
       " 0.9327181577682495,\n",
       " 0.9987924098968506,\n",
       " 0.6497654318809509,\n",
       " 0.9322507977485657,\n",
       " 0.9987843632698059,\n",
       " 0.9995642304420471,\n",
       " 0.9995642304420471,\n",
       " 0.9994563460350037,\n",
       " 0.9517091512680054,\n",
       " 0.3025017976760864]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob = [float(x) for x in model.predict([testX,testX,testX])]\n",
    "predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lables = []\n",
    "for x in predicted_prob:\n",
    "    if x>0.5:\n",
    "        predicted_lables.append(1)\n",
    "    else:\n",
    "        predicted_lables.append(0)\n",
    "predicted_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
