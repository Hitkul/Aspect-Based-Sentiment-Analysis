{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "import word2vecReader as godin_embedding\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    with open(filename,'r') as f:\n",
    "        foo = json.load(f)\n",
    "    return foo['sentence'],foo['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/final_dev.json\n"
     ]
    }
   ],
   "source": [
    "dataX,dataY = load_data_from_file('dataset/final_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data len\n",
      "111 111\n"
     ]
    }
   ],
   "source": [
    "print('data len')\n",
    "print(len(dataX),len(dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 1,count 0\n",
      "49 62\n"
     ]
    }
   ],
   "source": [
    "print('count 1,count 0')\n",
    "print(dataY.count(1),dataY.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(punctuation.replace('$',''))\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #removing stock names to see if it helps\n",
    "#     sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "#     remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train set\n"
     ]
    }
   ],
   "source": [
    "print('cleaning train set')\n",
    "dataX = [clean_sentence(x) for x in dataX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataY = to_categorical(dataY,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lengths = [len(s.split()) for s in dataX]\n",
    "max_length = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading word2vec model, this can take some time...\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading goding model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading goding model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,sentence,godin_flag = False):\n",
    "    tokens = sentence.split()[:max_length]\n",
    "    if godin_flag:\n",
    "        embedding_matrix = np.zeros((max_length,400))\n",
    "    else:\n",
    "        embedding_matrix = np.zeros((max_length,300))\n",
    "    for i,word in enumerate(tokens):\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulding word2vec matrix of train set\n",
      "bulding godin matrix of train set\n"
     ]
    }
   ],
   "source": [
    "print(\"bulding word2vec matrix of train set\")\n",
    "train_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in dataX])\n",
    "print(\"bulding godin matrix of train set\")\n",
    "train_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in dataX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array = [train_godin,train_word2vec,train_godin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('models/bestSenti.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918918918918919"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(pred,dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('top20models/emb_key.json') as f:\n",
    "#     top_models = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_prediction_of_top_n_model(n):\n",
    "#     pred_n = []\n",
    "#     for x in range(1,n+1):\n",
    "#         print('predicting for model rank',x)\n",
    "#         model_name = top_models[str(x)]['key']\n",
    "#         model_embeddings = top_models[str(x)]['embeddings']\n",
    "#         input_array = [train_word2vec if x=='embedding_matrix_word2vec' else train_godin for x in model_embeddings]\n",
    "#         model = load_model('top20models/'+str(model_name)+'.h5')\n",
    "#         pred_n.append(model.predict(input_array))\n",
    "#         del model\n",
    "#     return pred_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_ensemble_pred(pred_n):\n",
    "#     pred = []\n",
    "#     n_of_pred = len(pred_n)\n",
    "#     n_of_sampels = len(pred_n[0])\n",
    "#     for x in range(n_of_sampels):\n",
    "#         sum_0 = 0.0\n",
    "#         sum_1 = 0.0\n",
    "#         for v in pred_n:\n",
    "#             sum_0+=v[x][0]\n",
    "#             sum_1+=v[x][1]\n",
    "#         pred.append(np.asarray([sum_0/n_of_pred,sum_1/n_of_pred],dtype=np.float32))\n",
    "#     return np.asarray(pred,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_acc(pred,dataY):\n",
    "#     pred_class = np.asarray([np.asarray([1,0],dtype=np.float32) if x[0]>x[1] else np.asarray([0,1],dtype=np.float32) for x in pred])\n",
    "#     count = [True if x[0]==y[0] else False for x,y in zip(pred_class,dataY)]\n",
    "#     return float(count.count(True))/len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_n = get_prediction_of_top_n_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = get_ensemble_pred(pred_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_acc(pred,dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_top_models = []\n",
    "# acc_score = []\n",
    "# n_of_top_model_to_use = 20\n",
    "# pred_n = get_prediction_of_top_n_model(n_of_top_model_to_use)\n",
    "# print(\"now doing ensemble\")\n",
    "# for i in range(1,n_of_top_model_to_use+1):\n",
    "#     no_of_top_models.append(i)\n",
    "#     pred = get_ensemble_pred(pred_n[:i])\n",
    "#     acc_score.append(get_acc(pred,dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(no_of_top_models, acc_score)\n",
    "# plt.xlabel('Number of models in ensemble')\n",
    "# plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946428571428571"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_name = top_models[str(1)]['key']\n",
    "# model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_embeddings = top_models[str(1)]['embeddings']\n",
    "# model_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_array = [train_word2vec if x=='embedding_matrix_word2vec' else train_godin for x in model_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model('top20models/'+str(model_name)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_acc(pred,dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
