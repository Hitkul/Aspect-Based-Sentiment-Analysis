{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation,digits\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import word2vecReader as godin_embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [5,5]\n",
    "plt.style.use('seaborn-notebook')\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from aspect_specific_prob import get_normalized_sentence_relation_vector\n",
    "from math import sqrt\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed = 7\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    with open(filename,'r') as f:\n",
    "        foo = json.load(f)\n",
    "    sentence_id =[]    \n",
    "    sentence = []\n",
    "    sentence_snippet = []\n",
    "    sentence_target = []\n",
    "    score = []\n",
    "    for key in foo.keys():\n",
    "        for info in foo[key]['info']:\n",
    "            sentence_snippet.append(eval(info['snippets'])[0])\n",
    "            score.append(float(info['sentiment_score']))\n",
    "            sentence_target.append(info['target'])\n",
    "            sentence_id.append(key)\n",
    "            sentence.append(foo[key]['sentence'])\n",
    "    return sentence_id,sentence,sentence_snippet,sentence_target,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/master.json\n"
     ]
    }
   ],
   "source": [
    "sentence_id,sentence,sentence_snippet,sentence_target,score = load_data_from_file('dataset/master.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 1171, 1171, 1171, 1171)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_id),len(sentence),len(sentence_snippet),len(sentence_target),len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(series,old_range,new_range):\n",
    "    m = interp1d(old_range,new_range)\n",
    "    return [float(m(x)) for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rescale(score,[-1,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "    print(sentence)\n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "    print(sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    print(sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    print(sentence)\n",
    "    #removing stock names to see if it helps\n",
    "#     sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    sentence = sentence.replace(\"'s\",'')\n",
    "    sentence = sentence.replace(\"-\",' ')\n",
    "    print(sentence)\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    print(tokens)\n",
    "    #     remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    for w in stop_words:\n",
    "        print(w)\n",
    "    print(tokens)\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    print(tokens)\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    print(tokens)\n",
    "    tokens = [w.translate(remove_digits) for w in tokens]\n",
    "    print(tokens)\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data set\n"
     ]
    }
   ],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "print('cleaning data set')\n",
    "sentence = [clean_sentence(x) for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning targets\n"
     ]
    }
   ],
   "source": [
    "print('cleaning targets')\n",
    "sentence_target = [clean_sentence(x) for x in sentence_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ma http://stks.co/1cyn continues to consolidate / base here\n",
      "$ma http://stks.co/1cyn continues to consolidate / base here\n",
      "$ma  continues to consolidate / base here\n",
      "$ma  continues to consolidate / base here\n",
      "$ma  continues to consolidate / base here\n",
      "['ma', 'continues', 'to', 'consolidate', '', 'base', 'here']\n",
      "<WordListCorpusReader in '/home/hitkul/nltk_data/corpora/stopwords'>\n",
      "['continues', 'consolidate', '', 'base']\n",
      "['continues', 'consolidate', 'base']\n",
      "['continues', 'consolidate', 'base']\n",
      "['continues', 'consolidate', 'base']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'continues consolidate base'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence(\"$MA http://stks.co/1CYN continues to consolidate / base here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = np.asarray(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(s.split()) for s in sentence]\n",
    "max_length = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01186071, 0.04222412, 0.0972578 , 0.1892969 , 0.07401082,\n",
       "        0.06879211, 0.03747984, 0.02324699, 0.00948857, 0.00189771]),\n",
       " array([ 1. ,  2.8,  4.6,  6.4,  8.2, 10. , 11.8, 13.6, 15.4, 17.2, 19. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAJGCAYAAAB/dsKFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfd363e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "plt.hist(lengths, normed=True,edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_print(s,target):\n",
    "    global count\n",
    "    count+=1\n",
    "    if count%10==0:\n",
    "        print(count)\n",
    "    print(s)\n",
    "    return get_normalized_sentence_relation_vector(s,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iaci looks good weekly chart\n",
      "pcln back trendline \n",
      "rt nflx close looking good bulls hold positions see close keep buying\n",
      "profit taking aapl morning pressure stock im still bullish aapl\n",
      "skx turning coming far could go far stock price implies pay nothing business\n",
      "mos looking good  calls active month weekly\n",
      "sold tza  put hedging  call letting calls ride solo\n",
      "ymi long setup closed ma macd cross november catalyst\n",
      "tzoo close  ready rock roll\n",
      "10\n",
      "im liking price action swks currently  target  year end\n",
      "wft closng higher\n",
      "sppi building rs sweet want break new week earnings growth justifies way higher\n",
      "spy bull move ended waiting next setup\n",
      "double bottom handle buy point  ip\n",
      "gld daily chart though rsi stoch point possible move lot resistance\n",
      "acom downside breakout looks coming soon\n",
      "zagg getting readytarget  plus close  better avg daily volume\n",
      "volatility squeeze aapl hope gets resolved upside\n",
      "still short lng  areanext stop could  someone slammed hard  shs follow\n",
      "20\n",
      "covered small mww short   loss flat day cash\n",
      "bearish outside day tuesday significant  day resistance still intact opinion sds\n",
      "rt fitzstock iyt transports always lead way broke dt line st macd cross bull flag\n",
      "dug weekly stochastics finally starting turn long consolidation buying\n",
      "spy dont hang bull hat yet next week pop higher qe hope back fed day meeting\n",
      "longed amzn  \n",
      "slw weekly  calls     volume worth chance jmho\n",
      "hsc receives year m contract new saudi arabian steel mill\n",
      "reuters green mountain revenue misses shares plunge gmcr prints  market foul mood bad day disappoint\n",
      "xlf bounced target buy area bought skf hedge watch ma slope\n",
      "30\n",
      "vxx adding position\n",
      "gps gap september comparable store sales\n",
      "double bottom handle buy point  wmt\n",
      "continues consolidate base\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-360-5e369cde0c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentence_enchance_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprogress_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-360-5e369cde0c1f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentence_enchance_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprogress_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-359-928f524ef0da>\u001b[0m in \u001b[0;36mprogress_print\u001b[0;34m(s, target)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_normalized_sentence_relation_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/try/Sentiment-analysis/aspect_specific_prob.py\u001b[0m in \u001b[0;36mget_normalized_sentence_relation_vector\u001b[0;34m(s, targets)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_normalized_sentence_relation_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0msentence_relation_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentence_tokens_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0msentence_relation_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrenormalize_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_relation_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence_relation_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/try/Sentiment-analysis/aspect_specific_prob.py\u001b[0m in \u001b[0;36mget_sentence_tokens_prob\u001b[0;34m(s, targets)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mtarget_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtarget_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0ms_prob_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sentence_enchance_prob = [progress_print(x,[y]) for x,y in zip(sentence[500:600],sentence_target[500:600])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,sentence,godin_flag = False):\n",
    "    tokens = sentence.split()[:max_length]\n",
    "    if godin_flag:\n",
    "        embedding_matrix = np.zeros((max_length,400))\n",
    "    else:\n",
    "        embedding_matrix = np.zeros((max_length,300))\n",
    "    for i,word in enumerate(tokens):\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulding word2vec matrix of data set\n",
      "bulding godin matrix of data set\n"
     ]
    }
   ],
   "source": [
    "print(\"bulding word2vec matrix of data set\")\n",
    "data_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in dataX])\n",
    "print(\"bulding godin matrix of data set\")\n",
    "data_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in dataX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=2, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sk_mse(y_true,y_pred):\n",
    "     return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(length,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3):\n",
    "    # channel 1\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs1 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs1 = Input(shape=(length,400))\n",
    "#     if em_c1 == 'free':\n",
    "#         embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "#     else:\n",
    "#         embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag)(inputs1)\n",
    "\n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    if em_c2 == 'embedding_matrix_word2vec':\n",
    "        inputs2 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs2 = Input(shape=(length,400))\n",
    "#     embedding2 = Embedding(vocab_size, 400, weights = [embedding_matrix_godin],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "#     if em_c2 == 'free':\n",
    "#         embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "#     else:\n",
    "#         embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(inputs2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs3 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs3 = Input(shape=(length,400))\n",
    "#     embedding3 = Embedding(vocab_size, 400)(inputs3)\n",
    "#     if em_c3 == 'free':\n",
    "#         embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "#     else:\n",
    "#         embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(inputs3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[sk_mse])\n",
    "    # summarize\n",
    "#     print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dropout = Real(low=0.4, high=0.9,name = 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_n_filters = Categorical(categories=[100,200,300,400],name='n_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_filter_size_c1 = Integer(low=1,high=6,name = 'filter_size_c1')\n",
    "para_filter_size_c2 = Integer(low=1,high=6,name = 'filter_size_c2')\n",
    "para_filter_size_c3 = Integer(low=1,high=6,name = 'filter_size_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_em_c1 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c1')\n",
    "para_em_c2 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c2')\n",
    "para_em_c3 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_epoch = Categorical(categories=[10,20,30,50],name='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size_c1,para_filter_size_c2,para_filter_size_c3,para_em_c1,para_em_c2,para_em_c3,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_parameters = [0.0006973763486468701,0.9,400,300,1,1,1,'embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_godin',8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = dict()\n",
    "key=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=parameters)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch):\n",
    "# n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag\n",
    "    # Print the hyper-parameters.\n",
    "    global key\n",
    "    global record\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    print('learning rate ==>',learning_rate)\n",
    "    print('dropout==>',dropout)\n",
    "    print('n_dense==>',n_dense)\n",
    "    print('n_filters==>',n_filters)\n",
    "    print('filter_size_c1',filter_size_c1)\n",
    "    print('filter_size_c2',filter_size_c2)\n",
    "    print('filter_size_c3',filter_size_c3)\n",
    "    print('em_c1==>',em_c1)\n",
    "    print('em_c2==>',em_c2)\n",
    "    print('em_c3==>',em_c3)\n",
    "    print('batch_size==>',batch_size)\n",
    "    print('epocs==>',epoch)\n",
    "\n",
    "    \n",
    "    cv_mse=[]\n",
    "    cv_r2=[]\n",
    "    for train,test in kfold.split(dataX,dataY):\n",
    "        model = define_model(length = max_length,\n",
    "                             n_dense=n_dense,\n",
    "                             dropout=dropout,\n",
    "                             learning_rate=learning_rate,\n",
    "                             n_filters=n_filters,\n",
    "                             filter_size_c1=int(filter_size_c1),\n",
    "                             filter_size_c2=int(filter_size_c2),\n",
    "                             filter_size_c3=int(filter_size_c3),\n",
    "                             em_c1=em_c1,\n",
    "                             em_c2=em_c2,\n",
    "                             em_c3=em_c3)\n",
    "        \n",
    "        input_array_train = [data_word2vec[train] if x=='embedding_matrix_word2vec' else data_godin[train] for x in [em_c1,em_c2,em_c3]]\n",
    "        input_array_test = [data_word2vec[test] if x=='embedding_matrix_word2vec' else data_godin[test] for x in [em_c1,em_c2,em_c3]]\n",
    "        \n",
    "        trainY = dataY[train]\n",
    "        testY = dataY[test]\n",
    "        \n",
    "        history_object = model.fit(input_array_train,trainY,epochs=epoch, batch_size=batch_size)\n",
    "        pred = model.predict(input_array_test)\n",
    "        pred_val = [x[0] for x in pred]\n",
    "        pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "        testY = rescale(testY,[0,1],[-1,1])\n",
    "        m = mean_squared_error(testY,pred_val)\n",
    "        r2 = r2_score(testY,pred_val)\n",
    "        print(m,r2)\n",
    "        cv_mse.append(m)\n",
    "        cv_r2.append(r2)\n",
    "    mse_mean = np.mean(cv_mse)\n",
    "    r2_mean = np.mean(cv_r2)\n",
    "    print(cv_mse)\n",
    "    print(cv_r2)\n",
    "    print(mse_mean)\n",
    "    print(r2_mean)\n",
    "    \n",
    "    record[key] = {'parameters':[learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch],'mse_mean':mse_mean,'r2_mean':r2_mean,'cv_mse':cv_mse,'cv_r2':cv_r2}\n",
    "        \n",
    "    with open('models/record.json', 'w') as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    \n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -mse_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=1------------------\n",
      "learning rate ==> 0.0006973763486468701\n",
      "dropout==> 0.9\n",
      "n_dense==> 400\n",
      "n_filters==> 300\n",
      "filter_size_c1 6\n",
      "filter_size_c2 2\n",
      "filter_size_c3 4\n",
      "em_c1==> embedding_matrix_godin\n",
      "em_c2==> embedding_matrix_word2vec\n",
      "em_c3==> embedding_matrix_godin\n",
      "batch_size==> 8\n",
      "epocs==> 10\n",
      "Epoch 1/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.7015 - sk_mse: 0.0471\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6877 - sk_mse: 0.0406\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6742 - sk_mse: 0.0344\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6644 - sk_mse: 0.0296\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6602 - sk_mse: 0.0274\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6547 - sk_mse: 0.0247\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6475 - sk_mse: 0.0213\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6473 - sk_mse: 0.0213\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6416 - sk_mse: 0.0185\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6390 - sk_mse: 0.0174\n",
      "0.14132236347591814 0.09586239315212086\n",
      "Epoch 1/10\n",
      "586/586 [==============================] - 5s 9ms/step - loss: 0.6994 - sk_mse: 0.0452\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6817 - sk_mse: 0.0373\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6708 - sk_mse: 0.0320\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6678 - sk_mse: 0.0304: 0s - loss:\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6575 - sk_mse: 0.0256\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6526 - sk_mse: 0.0231\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 5s 9ms/step - loss: 0.6460 - sk_mse: 0.0200\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6451 - sk_mse: 0.0194\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6390 - sk_mse: 0.0164\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6386 - sk_mse: 0.0166\n",
      "0.13792750767274037 0.14872495920935613\n",
      "[0.14132236347591814, 0.13792750767274037]\n",
      "[0.09586239315212086, 0.14872495920935613]\n",
      "0.13962493557432926\n",
      "0.1222936761807385\n",
      "-----------------------------combination no=2------------------\n",
      "learning rate ==> 0.0033518465729761387\n",
      "dropout==> 0.6318539798339841\n",
      "n_dense==> 100\n",
      "n_filters==> 100\n",
      "filter_size_c1 5\n",
      "filter_size_c2 5\n",
      "filter_size_c3 3\n",
      "em_c1==> embedding_matrix_godin\n",
      "em_c2==> embedding_matrix_word2vec\n",
      "em_c3==> embedding_matrix_godin\n",
      "batch_size==> 64\n",
      "epocs==> 10\n",
      "Epoch 1/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6928 - sk_mse: 0.0435\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6693 - sk_mse: 0.0321\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6508 - sk_mse: 0.0229\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6360 - sk_mse: 0.0160\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6293 - sk_mse: 0.0129\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6232 - sk_mse: 0.0095\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6213 - sk_mse: 0.0090\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6160 - sk_mse: 0.0065\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6166 - sk_mse: 0.0068\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6164 - sk_mse: 0.0067\n",
      "0.1315736062551857 0.15823198425223006\n",
      "Epoch 1/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6982 - sk_mse: 0.0449\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6758 - sk_mse: 0.0346\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6577 - sk_mse: 0.0259\n",
      "Epoch 4/10\n",
      "128/586 [=====>........................] - ETA: 0s - loss: 0.6364 - sk_mse: 0.0152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f5b44a4ceba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-5565f2167c9c>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size_c1, filter_size_c2, filter_size_c3, em_c1, em_c2, em_c3, batch_size, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"traning done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10343218728427603 0.3093617125885538\n",
      "0.11082901716092575 0.3214193870990977\n",
      "0.10922397337212918 0.2996706946188652\n",
      "0.12080560219923858 0.27274889295718263\n",
      "0.10764737821782466 0.3265275466674228\n"
     ]
    }
   ],
   "source": [
    "# for train,test in kfold.split(dataX,dataY):\n",
    "#     model = define_model(length = max_length,\n",
    "#                          n_dense=400,\n",
    "#                          dropout=0.9,\n",
    "#                          learning_rate=0.0006973763486468701,\n",
    "#                          n_filters=300,\n",
    "#                          filter_size_c1=1,\n",
    "#                          filter_size_c2=1,\n",
    "#                          filter_size_c3=1,\n",
    "#                          em_c1='embedding_matrix_godin',\n",
    "#                          em_c2='embedding_matrix_word2vec',\n",
    "#                          em_c3='embedding_matrix_godin')\n",
    "#     input_array_train = [data_godin[train],data_word2vec[train],data_godin[train]]\n",
    "#     input_array_test = [data_godin[test],data_word2vec[test],data_godin[test]]\n",
    "#     trainY = dataY[train]\n",
    "#     testY = dataY[test]\n",
    "#     history_object = model.fit(input_array_train,trainY,epochs=30, batch_size=8,verbose=0)\n",
    "#     pred = model.predict(input_array_test)\n",
    "#     pred_val = [x[0] for x in pred]\n",
    "#     pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "#     testY = rescale(testY,[0,1],[-1,1])\n",
    "#     m = mean_squared_error(testY,pred_val)\n",
    "#     r2 = r2_score(testY,pred_val)\n",
    "#     print(m,r2)\n",
    "#     cv_mse.append(m)\n",
    "#     cv_r2.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_mse), np.std(cv_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_r2), np.std(cv_r2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_array_train = [train_godin,train_word2vec,train_godin]\n",
    "# input_array_test = [test_godin,test_word2vec,test_godin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history_object = model.fit(input_array_train, trainY,epochs=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(input_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_val = [x[0] for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_val = rescale(pred_val)\n",
    "# testY = rescale(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(testY,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r2_score(testY,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i,y in zip(pred_val,testY):\n",
    "#     print(i,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
