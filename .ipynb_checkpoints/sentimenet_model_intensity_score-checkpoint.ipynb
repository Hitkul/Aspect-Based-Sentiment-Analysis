{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import word2vecReader as godin_embedding\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from gensim.models import KeyedVectors\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    with open(filename,'r') as f:\n",
    "        foo = json.load(f)\n",
    "        \n",
    "    sentence = []\n",
    "    score = []\n",
    "    for key in foo.keys():\n",
    "        for info in foo[key]['info']:\n",
    "#             print(eval(info['snippets'])[0])\n",
    "            sentence.append(eval(info['snippets'])[0])\n",
    "            score.append(float(info['sentiment_score']))\n",
    "#         sentence_id.append(key)\n",
    "#         sentence.append(foo[key]['sentence'])\n",
    "#         score.append(float(foo[key]['info'][0]['sentiment_score']))\n",
    "    return sentence,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/master_train.json\n",
      "loading file =  dataset/master_test.json\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY = load_data_from_file('dataset/master_train.json')\n",
    "testX,testY = load_data_from_file('dataset/master_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 1060)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX),len(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 111)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testX),len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(series):\n",
    "    m = interp1d([-1,1],[0,1])\n",
    "    return [float(m(x)) for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = rescale(trainY)\n",
    "testY = rescale(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(punctuation.replace('$',''))\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #removing stock names to see if it helps\n",
    "#     sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "#     remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train set\n",
      "cleaning test set\n"
     ]
    }
   ],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "print('cleaning train set')\n",
    "trainX = [clean_sentence(x) for x in trainX]\n",
    "print('cleaning test set')\n",
    "testX = [clean_sentence(x) for x in testX]\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 1060\n",
      "111 111\n"
     ]
    }
   ],
   "source": [
    "print(len(trainX),len(trainY))\n",
    "print(len(testX),len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = np.asarray(trainY)\n",
    "testY = np.asarray(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(s.split()) for s in trainX]\n",
    "max_length = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11792453, 0.15902965, 0.26347709, 0.07816712, 0.0458221 ,\n",
       "        0.04312668, 0.00269542, 0.00336927, 0.        , 0.00067385]),\n",
       " array([ 1. ,  2.4,  3.8,  5.2,  6.6,  8. ,  9.4, 10.8, 12.2, 13.6, 15. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAJCCAYAAADUa5GyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa12551198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "plt.hist(lengths, normed=True,edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,sentence,godin_flag = False):\n",
    "    tokens = sentence.split()[:max_length]\n",
    "    if godin_flag:\n",
    "        embedding_matrix = np.zeros((max_length,400))\n",
    "    else:\n",
    "        embedding_matrix = np.zeros((max_length,300))\n",
    "    for i,word in enumerate(tokens):\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulding word2vec matrix of train set\n",
      "bulding godin matrix of train set\n",
      "bulding word2vec matrix of dev set\n",
      "bulding godin matrix of dev set\n"
     ]
    }
   ],
   "source": [
    "print(\"bulding word2vec matrix of train set\")\n",
    "train_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in trainX])\n",
    "print(\"bulding godin matrix of train set\")\n",
    "train_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in trainX])\n",
    "print(\"bulding word2vec matrix of dev set\")\n",
    "test_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in testX])\n",
    "print(\"bulding godin matrix of dev set\")\n",
    "test_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in testX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(length,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3):\n",
    "    # channel 1\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs1 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs1 = Input(shape=(length,400))\n",
    "#     if em_c1 == 'free':\n",
    "#         embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "#     else:\n",
    "#         embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag)(inputs1)\n",
    "\n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    if em_c2 == 'embedding_matrix_word2vec':\n",
    "        inputs2 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs2 = Input(shape=(length,400))\n",
    "#     embedding2 = Embedding(vocab_size, 400, weights = [embedding_matrix_godin],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "#     if em_c2 == 'free':\n",
    "#         embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "#     else:\n",
    "#         embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(inputs2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs3 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs3 = Input(shape=(length,400))\n",
    "#     embedding3 = Embedding(vocab_size, 400)(inputs3)\n",
    "#     if em_c3 == 'free':\n",
    "#         embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "#     else:\n",
    "#         embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(inputs3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 15, 400)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 15, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 15, 400)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 15, 300)      120300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 15, 300)      90300       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 15, 300)      120300      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15, 300)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 15, 300)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15, 300)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 7, 300)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 7, 300)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 7, 300)       0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2100)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2100)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2100)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6300)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 400)          2520400     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            401         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,851,701\n",
      "Trainable params: 2,851,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = define_model(length = max_length,\n",
    "                         n_dense=400,\n",
    "                         dropout=0.9,\n",
    "                         learning_rate=0.0006973763486468701,\n",
    "                         n_filters=300,\n",
    "                         filter_size_c1=1,\n",
    "                         filter_size_c2=1,\n",
    "                         filter_size_c3=1,\n",
    "                         em_c1='embedding_matrix_godin',\n",
    "                         em_c2='embedding_matrix_word2vec',\n",
    "                         em_c3='embedding_matrix_godin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array_train = [train_godin,train_word2vec,train_godin]\n",
    "input_array_test = [test_godin,test_word2vec,test_godin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1060/1060 [==============================] - 7s 6ms/step - loss: 0.7030 - acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6803 - acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6757 - acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1060/1060 [==============================] - 6s 5ms/step - loss: 0.6727 - acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6675 - acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1060/1060 [==============================] - 7s 6ms/step - loss: 0.6622 - acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6597 - acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1060/1060 [==============================] - 6s 5ms/step - loss: 0.6549 - acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6478 - acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1060/1060 [==============================] - 6s 5ms/step - loss: 0.6508 - acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6453 - acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6446 - acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6476 - acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6402 - acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6428 - acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6374 - acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6378 - acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6350 - acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6319 - acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6329 - acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6345 - acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6318 - acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6302 - acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6271 - acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1060/1060 [==============================] - 7s 6ms/step - loss: 0.6285 - acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6279 - acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1060/1060 [==============================] - 7s 7ms/step - loss: 0.6270 - acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6287 - acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1060/1060 [==============================] - 6s 6ms/step - loss: 0.6273 - acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1060/1060 [==============================] - 6s 5ms/step - loss: 0.6271 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_object = model.fit(input_array_train, trainY,epochs=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(input_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45930576],\n",
       "       [0.6662103 ],\n",
       "       [0.6048143 ],\n",
       "       [0.5265722 ],\n",
       "       [0.5638292 ],\n",
       "       [0.41839778],\n",
       "       [0.6833506 ],\n",
       "       [0.6403677 ],\n",
       "       [0.73781073],\n",
       "       [0.44848305],\n",
       "       [0.58691794],\n",
       "       [0.38973615],\n",
       "       [0.49810734],\n",
       "       [0.61973965],\n",
       "       [0.5701052 ],\n",
       "       [0.47699702],\n",
       "       [0.48535568],\n",
       "       [0.7042414 ],\n",
       "       [0.3593302 ],\n",
       "       [0.5367767 ],\n",
       "       [0.6452152 ],\n",
       "       [0.5450872 ],\n",
       "       [0.6672957 ],\n",
       "       [0.62869024],\n",
       "       [0.4810314 ],\n",
       "       [0.70106024],\n",
       "       [0.7215318 ],\n",
       "       [0.73103505],\n",
       "       [0.45487133],\n",
       "       [0.4542458 ],\n",
       "       [0.62715244],\n",
       "       [0.58339554],\n",
       "       [0.4592677 ],\n",
       "       [0.62891716],\n",
       "       [0.6169212 ],\n",
       "       [0.4237288 ],\n",
       "       [0.43100768],\n",
       "       [0.529949  ],\n",
       "       [0.47156122],\n",
       "       [0.63502467],\n",
       "       [0.41839778],\n",
       "       [0.34912786],\n",
       "       [0.64972746],\n",
       "       [0.64199185],\n",
       "       [0.6582677 ],\n",
       "       [0.49070525],\n",
       "       [0.7031169 ],\n",
       "       [0.5144107 ],\n",
       "       [0.64957696],\n",
       "       [0.40118998],\n",
       "       [0.5474911 ],\n",
       "       [0.62772256],\n",
       "       [0.574388  ],\n",
       "       [0.41839778],\n",
       "       [0.55708313],\n",
       "       [0.39303708],\n",
       "       [0.6247756 ],\n",
       "       [0.39422256],\n",
       "       [0.42051238],\n",
       "       [0.69479114],\n",
       "       [0.5397454 ],\n",
       "       [0.3579727 ],\n",
       "       [0.6440779 ],\n",
       "       [0.4641633 ],\n",
       "       [0.5824765 ],\n",
       "       [0.45586494],\n",
       "       [0.5363763 ],\n",
       "       [0.45163402],\n",
       "       [0.5700244 ],\n",
       "       [0.6772927 ],\n",
       "       [0.73015666],\n",
       "       [0.61057276],\n",
       "       [0.47336686],\n",
       "       [0.72534084],\n",
       "       [0.50873256],\n",
       "       [0.41397578],\n",
       "       [0.6382919 ],\n",
       "       [0.3277723 ],\n",
       "       [0.3290453 ],\n",
       "       [0.6227718 ],\n",
       "       [0.5846688 ],\n",
       "       [0.4126132 ],\n",
       "       [0.4567705 ],\n",
       "       [0.5076849 ],\n",
       "       [0.639655  ],\n",
       "       [0.33224773],\n",
       "       [0.72369224],\n",
       "       [0.46119958],\n",
       "       [0.7144464 ],\n",
       "       [0.54042625],\n",
       "       [0.55147505],\n",
       "       [0.42414168],\n",
       "       [0.5713668 ],\n",
       "       [0.53865254],\n",
       "       [0.61147374],\n",
       "       [0.6481762 ],\n",
       "       [0.61412203],\n",
       "       [0.7215318 ],\n",
       "       [0.4797606 ],\n",
       "       [0.3906988 ],\n",
       "       [0.60997146],\n",
       "       [0.66284657],\n",
       "       [0.5950901 ],\n",
       "       [0.5405805 ],\n",
       "       [0.43183905],\n",
       "       [0.6438377 ],\n",
       "       [0.68407476],\n",
       "       [0.53516805],\n",
       "       [0.6165232 ],\n",
       "       [0.6086536 ],\n",
       "       [0.4992393 ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = [x[0] for x in pred]\n",
    "# pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
