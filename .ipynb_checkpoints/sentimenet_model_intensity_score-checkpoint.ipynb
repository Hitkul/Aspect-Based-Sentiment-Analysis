{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation,digits\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import word2vecReader as godin_embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [5,5]\n",
    "plt.style.use('seaborn-notebook')\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from aspect_specific_prob import get_normalized_sentence_relation_vector\n",
    "from math import sqrt\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    with open(filename,'r') as f:\n",
    "        foo = json.load(f)\n",
    "    sentence_id =[]    \n",
    "    sentence = []\n",
    "    sentence_snippet = []\n",
    "    sentence_target = []\n",
    "    score = []\n",
    "    for key in foo.keys():\n",
    "        for info in foo[key]['info']:\n",
    "            sentence_snippet.append(eval(info['snippets'])[0])\n",
    "            score.append(float(info['sentiment_score']))\n",
    "            sentence_target.append(info['target'])\n",
    "            sentence_id.append(key)\n",
    "            sentence.append(foo[key]['sentence'])\n",
    "    return sentence_id,sentence,sentence_snippet,sentence_target,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/master_train.json\n"
     ]
    }
   ],
   "source": [
    "sentence_id,sentence,sentence_snippet,sentence_target,score = load_data_from_file('dataset/master_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 1171, 1171, 1171, 1171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_id),len(sentence),len(sentence_snippet),len(sentence_target),len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(series,old_range,new_range):\n",
    "    m = interp1d(old_range,new_range)\n",
    "    return [float(m(x)) for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rescale(score,[-1,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "#     print(sentence)\n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "#     print(sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "#     print(sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "#     print(sentence)\n",
    "    #removing stock names to see if it helps\n",
    "#     sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    sentence = sentence.replace(\"'s\",'')\n",
    "    sentence = sentence.replace(\"-\",' ')\n",
    "#     print(sentence)\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "#     print(tokens)\n",
    "    #     remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "#     for w in stop_words:\n",
    "#         print(w)\n",
    "#     print(tokens)\n",
    "    # filter out short tokens\n",
    "#     tokens = [word for word in tokens if len(word) > 1]\n",
    "#     print(tokens)\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "#     print(tokens)\n",
    "    tokens = [w.translate(remove_digits) for w in tokens]\n",
    "    tokens = [w.strip() for w in tokens]\n",
    "    tokens = [w for w in tokens if w!=\"\"]\n",
    "#     print(tokens)\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data set\n"
     ]
    }
   ],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "print('cleaning data set')\n",
    "sentence = [clean_sentence(x) for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning targets\n"
     ]
    }
   ],
   "source": [
    "print('cleaning targets')\n",
    "sentence_target = [clean_sentence(x) for x in sentence_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = np.asarray(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(s.split()) for s in sentence]\n",
    "max_length = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02712614, 0.06329432, 0.15371477, 0.1049882 , 0.12457929,\n",
       "        0.04370322, 0.02210278, 0.02963782, 0.0140654 , 0.00502336]),\n",
       " array([ 2. ,  3.7,  5.4,  7.1,  8.8, 10.5, 12.2, 13.9, 15.6, 17.3, 19. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAJGCAYAAAByaLLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAz4/0ctbqiBiiNRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5688bcecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "plt.hist(lengths, normed=True,edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progress_print(s,target):\n",
    "    global count\n",
    "    count+=1\n",
    "    if count%10==0:\n",
    "        print(count)\n",
    "#     print(s)\n",
    "    return get_normalized_sentence_relation_vector(s,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sentence_enchance_prob = [progress_print(x,[y]) for x,y in zip(sentence,sentence_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,sentence,prob_vector,godin_flag = False):\n",
    "    tokens = sentence.split()[:max_length]\n",
    "    if godin_flag:\n",
    "        embedding_matrix = np.zeros((max_length,400))\n",
    "    else:\n",
    "        embedding_matrix = np.zeros((max_length,300))\n",
    "    for i,word in enumerate(tokens):\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "            embedding_matrix[i]*=prob_vector[i]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulding word2vec matrix of data set\n",
      "bulding godin matrix of data set\n"
     ]
    }
   ],
   "source": [
    "print(\"bulding word2vec matrix of data set\")\n",
    "sentence_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x,y[0]) for x,y in zip(sentence,sentence_enchance_prob)])\n",
    "print(\"bulding godin matrix of data set\")\n",
    "sentence_godin = np.asarray([get_embedding_matrix(godin_model,x,y[0],godin_flag=True) for x,y in zip(sentence,sentence_enchance_prob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"bulding word2vec matrix of data set\")\n",
    "# data_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in dataX])\n",
    "# print(\"bulding godin matrix of data set\")\n",
    "# data_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in dataX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sk_mse(y_true,y_pred):\n",
    "     return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(length,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3):\n",
    "    # channel 1\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs1 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs1 = Input(shape=(length,400))\n",
    "#     if em_c1 == 'free':\n",
    "#         embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "#     else:\n",
    "#         embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag)(inputs1)\n",
    "\n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    if em_c2 == 'embedding_matrix_word2vec':\n",
    "        inputs2 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs2 = Input(shape=(length,400))\n",
    "#     embedding2 = Embedding(vocab_size, 400, weights = [embedding_matrix_godin],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "#     if em_c2 == 'free':\n",
    "#         embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "#     else:\n",
    "#         embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(inputs2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs3 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs3 = Input(shape=(length,400))\n",
    "#     embedding3 = Embedding(vocab_size, 400)(inputs3)\n",
    "#     if em_c3 == 'free':\n",
    "#         embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "#     else:\n",
    "#         embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(inputs3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[sk_mse])\n",
    "    # summarize\n",
    "#     print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = define_model(length = max_length,\n",
    "                         n_dense=400,\n",
    "                         dropout=0.8675199417083123,\n",
    "                         learning_rate=0.00997590314174646,\n",
    "                         n_filters=100,\n",
    "                         filter_size_c1=2,\n",
    "                         filter_size_c2=3,\n",
    "                         filter_size_c3=2,\n",
    "                         em_c1='embedding_matrix_godin',\n",
    "                         em_c2='embedding_matrix_word2vec',\n",
    "                         em_c3='embedding_matrix_godin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array_train = [sentence_godin,sentence_word2vec,sentence_godin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1171/1171 [==============================] - 2s 2ms/step - loss: 0.8860 - sk_mse: 0.0568\n",
      "Epoch 2/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6930 - sk_mse: 0.0417\n",
      "Epoch 3/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6920 - sk_mse: 0.0424\n",
      "Epoch 4/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6912 - sk_mse: 0.0418\n",
      "Epoch 5/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6874 - sk_mse: 0.0403\n",
      "Epoch 6/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6902 - sk_mse: 0.0409\n",
      "Epoch 7/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6893 - sk_mse: 0.0398\n",
      "Epoch 8/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6848 - sk_mse: 0.0388\n",
      "Epoch 9/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6928 - sk_mse: 0.0418\n",
      "Epoch 10/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6934 - sk_mse: 0.0413\n",
      "Epoch 11/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6925 - sk_mse: 0.0392\n",
      "Epoch 12/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.7046 - sk_mse: 0.0419\n",
      "Epoch 13/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6929 - sk_mse: 0.0397\n",
      "Epoch 14/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6915 - sk_mse: 0.0391\n",
      "Epoch 15/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6844 - sk_mse: 0.0371\n",
      "Epoch 16/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6970 - sk_mse: 0.0383\n",
      "Epoch 17/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6924 - sk_mse: 0.0390\n",
      "Epoch 18/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6921 - sk_mse: 0.0365\n",
      "Epoch 19/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6740 - sk_mse: 0.0327\n",
      "Epoch 20/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6853 - sk_mse: 0.0336\n",
      "Epoch 21/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6847 - sk_mse: 0.0333\n",
      "Epoch 22/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6747 - sk_mse: 0.0319\n",
      "Epoch 23/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6767 - sk_mse: 0.0320\n",
      "Epoch 24/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6768 - sk_mse: 0.0304\n",
      "Epoch 25/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6677 - sk_mse: 0.0288\n",
      "Epoch 26/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6639 - sk_mse: 0.0287\n",
      "Epoch 27/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6666 - sk_mse: 0.0288\n",
      "Epoch 28/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6672 - sk_mse: 0.0279\n",
      "Epoch 29/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6634 - sk_mse: 0.0282\n",
      "Epoch 30/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6561 - sk_mse: 0.0250\n",
      "Epoch 31/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6628 - sk_mse: 0.0277\n",
      "Epoch 32/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6603 - sk_mse: 0.0243\n",
      "Epoch 33/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6585 - sk_mse: 0.0250\n",
      "Epoch 34/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6518 - sk_mse: 0.0229\n",
      "Epoch 35/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6519 - sk_mse: 0.0231\n",
      "Epoch 36/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6553 - sk_mse: 0.0232\n",
      "Epoch 37/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6517 - sk_mse: 0.0229\n",
      "Epoch 38/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6508 - sk_mse: 0.0223\n",
      "Epoch 39/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6533 - sk_mse: 0.0233\n",
      "Epoch 40/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6542 - sk_mse: 0.0226\n",
      "Epoch 41/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6517 - sk_mse: 0.0223\n",
      "Epoch 42/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6601 - sk_mse: 0.0226\n",
      "Epoch 43/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6603 - sk_mse: 0.0226\n",
      "Epoch 44/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6528 - sk_mse: 0.0211\n",
      "Epoch 45/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6493 - sk_mse: 0.0215\n",
      "Epoch 46/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6529 - sk_mse: 0.0224\n",
      "Epoch 47/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6561 - sk_mse: 0.0224\n",
      "Epoch 48/50\n",
      "1171/1171 [==============================] - 2s 1ms/step - loss: 0.6519 - sk_mse: 0.0220\n",
      "Epoch 49/50\n",
      "1171/1171 [==============================] - 1s 1ms/step - loss: 0.6473 - sk_mse: 0.0206\n",
      "Epoch 50/50\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 0.6547 - sk_mse: 0.02 - 1s 1ms/step - loss: 0.6547 - sk_mse: 0.0202\n"
     ]
    }
   ],
   "source": [
    "history_object = model.fit(input_array_train,trainY,epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"models/sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv_mse=[]\n",
    "# cv_r2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train,test in kfold.split(sentence,score):\n",
    "#     model = define_model(length = max_length,\n",
    "#                          n_dense=400,\n",
    "#                          dropout=0.8675199417083123,\n",
    "#                          learning_rate=0.00997590314174646,\n",
    "#                          n_filters=100,\n",
    "#                          filter_size_c1=2,\n",
    "#                          filter_size_c2=3,\n",
    "#                          filter_size_c3=2,\n",
    "#                          em_c1='embedding_matrix_godin',\n",
    "#                          em_c2='embedding_matrix_word2vec',\n",
    "#                          em_c3='embedding_matrix_godin')\n",
    "    \n",
    "   \n",
    "#     input_array_train = [sentence_godin[train],sentence_word2vec[train],sentence_godin[train]]\n",
    "#     input_array_test = [sentence_godin[test],sentence_word2vec[test],sentence_godin[test]]\n",
    "#     trainY = score[train]\n",
    "#     testY = score[test]\n",
    "#     history_object = model.fit(input_array_train,trainY,epochs=50, batch_size=64,verbose=1)\n",
    "#     pred = model.predict(input_array_test)\n",
    "#     pred_val = [x[0] for x in pred]\n",
    "#     pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "#     testY = rescale(testY,[0,1],[-1,1])\n",
    "#     m = mean_squared_error(testY,pred_val)\n",
    "#     r2 = r2_score(testY,pred_val)\n",
    "#     print(m,r2)\n",
    "#     cv_mse.append(m)\n",
    "#     cv_r2.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_mse), np.std(cv_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_r2), np.std(cv_r2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_dropout = Real(low=0.4, high=0.9,name = 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_n_filters = Categorical(categories=[100,200,300,400],name='n_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_filter_size_c1 = Integer(low=1,high=6,name = 'filter_size_c1')\n",
    "# # para_filter_size_c2 = Integer(low=1,high=6,name = 'filter_size_c2')\n",
    "# para_filter_size_c3 = Integer(low=1,high=6,name = 'filter_size_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_em_c1 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c1')\n",
    "# para_em_c2 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c2')\n",
    "# para_em_c3 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_epoch = Categorical(categories=[10,20,30,50],name='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size_c1,para_filter_size_c2,para_filter_size_c3,para_em_c1,para_em_c2,para_em_c3,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default_parameters = [0.0006973763486468701,0.9,400,300,1,1,1,'embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_godin',8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record = dict()\n",
    "# key=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @use_named_args(dimensions=parameters)\n",
    "# def fitness(learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch):\n",
    "# # n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag\n",
    "#     # Print the hyper-parameters.\n",
    "#     global key\n",
    "#     global record\n",
    "#     print('-----------------------------combination no={0}------------------'.format(key))\n",
    "#     print('learning rate ==>',learning_rate)\n",
    "#     print('dropout==>',dropout)\n",
    "#     print('n_dense==>',n_dense)\n",
    "#     print('n_filters==>',n_filters)\n",
    "#     print('filter_size_c1',filter_size_c1)\n",
    "#     print('filter_size_c2',filter_size_c2)\n",
    "#     print('filter_size_c3',filter_size_c3)\n",
    "#     print('em_c1==>',em_c1)\n",
    "#     print('em_c2==>',em_c2)\n",
    "#     print('em_c3==>',em_c3)\n",
    "#     print('batch_size==>',batch_size)\n",
    "#     print('epocs==>',epoch)\n",
    "\n",
    "    \n",
    "#     cv_mse=[]\n",
    "#     cv_r2=[]\n",
    "#     for train,test in kfold.split(dataX,dataY):\n",
    "#         model = define_model(length = max_length,\n",
    "#                              n_dense=n_dense,\n",
    "#                              dropout=dropout,\n",
    "#                              learning_rate=learning_rate,\n",
    "#                              n_filters=n_filters,\n",
    "#                              filter_size_c1=int(filter_size_c1),\n",
    "#                              filter_size_c2=int(filter_size_c2),\n",
    "#                              filter_size_c3=int(filter_size_c3),\n",
    "#                              em_c1=em_c1,\n",
    "#                              em_c2=em_c2,\n",
    "#                              em_c3=em_c3)\n",
    "        \n",
    "#         input_array_train = [data_word2vec[train] if x=='embedding_matrix_word2vec' else data_godin[train] for x in [em_c1,em_c2,em_c3]]\n",
    "#         input_array_test = [data_word2vec[test] if x=='embedding_matrix_word2vec' else data_godin[test] for x in [em_c1,em_c2,em_c3]]\n",
    "        \n",
    "#         trainY = dataY[train]\n",
    "#         testY = dataY[test]\n",
    "        \n",
    "#         history_object = model.fit(input_array_train,trainY,epochs=epoch, batch_size=batch_size)\n",
    "#         pred = model.predict(input_array_test)\n",
    "#         pred_val = [x[0] for x in pred]\n",
    "#         pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "#         testY = rescale(testY,[0,1],[-1,1])\n",
    "#         m = mean_squared_error(testY,pred_val)\n",
    "#         r2 = r2_score(testY,pred_val)\n",
    "#         print(m,r2)\n",
    "#         cv_mse.append(m)\n",
    "#         cv_r2.append(r2)\n",
    "#     mse_mean = np.mean(cv_mse)\n",
    "#     r2_mean = np.mean(cv_r2)\n",
    "#     print(cv_mse)\n",
    "#     print(cv_r2)\n",
    "#     print(mse_mean)\n",
    "#     print(r2_mean)\n",
    "    \n",
    "#     record[key] = {'parameters':[learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch],'mse_mean':mse_mean,'r2_mean':r2_mean,'cv_mse':cv_mse,'cv_r2':cv_r2}\n",
    "        \n",
    "#     with open('models/record.json', 'w') as fout:\n",
    "#         json.dump(record,fout,indent=4)\n",
    "    \n",
    "#     key+=1\n",
    "    \n",
    "#     del model\n",
    "#     K.clear_session()\n",
    "    \n",
    "#     return -mse_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search_result = gp_minimize(func=fitness,\n",
    "#                             dimensions=parameters,\n",
    "#                             acq_func='EI',\n",
    "#                             n_calls=11,\n",
    "#                             x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"traning done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
