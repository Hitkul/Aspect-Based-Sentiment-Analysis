{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from os import remove\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import fasttext\n",
    "import csv\n",
    "import codecs\n",
    "import word2vecReader as godin_embedding\n",
    "from random import shuffle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from gensim.models import KeyedVectors\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    sentences = []\n",
    "    label = []\n",
    "    with codecs.open(filename, \"r\",encoding='utf-8', errors='ignore') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            try:\n",
    "                sentences.append(row[0])\n",
    "                label.append(row[1])\n",
    "            except:\n",
    "                print(row)\n",
    "    return sentences,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/final_train.csv\n",
      "loading file =  dataset/final_dev.csv\n"
     ]
    }
   ],
   "source": [
    "# sentences,score = load_data_from_xml('dataset/financial_posts_ABSA_train.xml')\n",
    "trainX,trainY = load_data_from_file('dataset/final_train.csv')\n",
    "devX,devY = load_data_from_file('dataset/final_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn a sentence into clean tokens\n",
    "def clean_sentence(sentence):\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", sentence)\n",
    "    #removing stock names to see if it helps\n",
    "    sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train set\n",
      "cleaning dev set\n"
     ]
    }
   ],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "print('cleaning train set')\n",
    "trainX = [clean_sentence(x) for x in trainX]\n",
    "print('cleaning dev set')\n",
    "devX = [clean_sentence(x) for x in devX]\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting real number scores to lables\n",
    "#0-->-ve sentiment 1-->+ve sentiment\n",
    "# labels = [1 if x >= 0 else 0 for x in score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def shuffle_data(sentences,labels,score):\n",
    "#     numbers = [i for i in range(len(sentences))]\n",
    "#     shuffle(numbers)\n",
    "#     temp_text = sentences\n",
    "#     temp_lables = labels\n",
    "#     temp_score = score\n",
    "#     for i in numbers:\n",
    "#         sentences[i] = temp_text[i]\n",
    "#         labels[i]=temp_lables[i]\n",
    "#         score[i] = temp_score[i]\n",
    "#     print(len(sentences))\n",
    "#     print(len(labels))\n",
    "#     print(len(score))\n",
    "#     return sentences,labels,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences,labels,score = shuffle_data(sentences,labels,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#doing train and train split\n",
    "# test_train_split_ratio =0.9\n",
    "# trainX,testX = sentences[:int(test_train_split_ratio*len(sentences))],sentences[int(test_train_split_ratio*len(sentences)):]\n",
    "# trainY,testY = labels[:int(test_train_split_ratio*len(labels))],labels[int(test_train_split_ratio*len(labels)):]\n",
    "# score_trainY,score_testY = score[:int(test_train_split_ratio*len(score))],score[int(test_train_split_ratio*len(score)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1569013 1569013\n",
      "16010 16010\n"
     ]
    }
   ],
   "source": [
    "print(len(trainX),len(trainY))\n",
    "print(len(devX),len(devY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting output matrix [-ve,+ve]\n",
    "devY = to_categorical(devY,2)\n",
    "trainY = to_categorical(trainY,2)\n",
    "# devY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 40\n",
      "Vocabulary size: 425344\n",
      "(1569013, 40) (16010, 40)\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = create_tokenizer(trainX)\n",
    "# calculate max document length\n",
    "lengths = [len(s.split()) for s in trainX]\n",
    "max_length = max(lengths)\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_length)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "# encode data\n",
    "trainX = encode_text(tokenizer, trainX, max_length)\n",
    "devX = encode_text(tokenizer, devX, max_length)\n",
    "print(trainX.shape,devX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.61457298e-02, 9.09814004e-02, 6.55047154e-02, 3.88071992e-02,\n",
       "        7.99626899e-03, 4.90435707e-04, 6.72397233e-05, 6.69210516e-06,\n",
       "        1.59335837e-07, 1.59335837e-07]),\n",
       " array([ 0.,  4.,  8., 12., 16., 20., 24., 28., 32., 36., 40.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAJCCAYAAADUa5GyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb89f4ebdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "plt.hist(lengths, normed=True,edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considring only few sentences have len >20, we can also take max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading GloVe embedding\n",
    "def load_GloVe_embedding(file_name):\n",
    "    embeddings_index = dict()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_GloVe_embedding_matrix(embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index_glove = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "embedding_matrix_glove = get_GloVe_embedding_matrix(embeddings_index_glove)\n",
    "# embedding_matrix[100]\n",
    "# e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')\n",
    "embedding_matrix_word2vec = get_word2vec_embedding_matrix(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fast text word embedding\n",
    "def load_fast_text_model(sentences):\n",
    "    try:\n",
    "        m = fasttext.load_model('fast_text_model.bin')\n",
    "        print(\"trained model loaded\")\n",
    "        return m\n",
    "    except:\n",
    "        print(\"traning new model\")\n",
    "        with open('temp_file.txt','w') as temp_file:\n",
    "            for sentence in sentences:\n",
    "#                 sentence = sentence.encode('UTF-8')\n",
    "#                 print(sentence)\n",
    "                temp_file.write(sentence)\n",
    "        m = fasttext.cbow('temp_file.txt','fast_text_model')\n",
    "        remove('temp_file.txt')\n",
    "        print('model trained')\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fast_text_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainLines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-05b364b06f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast_text_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fast_text_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLines\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtestLines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_matrix_fast_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fast_text_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_text_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainLines' is not defined"
     ]
    }
   ],
   "source": [
    "#need to fix this\n",
    "# fast_text_model = load_fast_text_model(trainX+testLines)\n",
    "# embedding_matrix_fast_text = get_fast_text_matrix(fast_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_godin_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,400))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "embedding_matrix_godin = get_godin_embedding_matrix(godin_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dropout = Real(low=0.4, high=0.9,name = 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_n_dense = Integer(low=100, high=400, name='n_dense')\n",
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para_n_filters = Integer(low=100,high=400,name='n_filters')\n",
    "para_n_filters = Categorical(categories=[100,200,300,400],name='n_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_filter_size_c1 = Integer(low=1,high=6,name = 'filter_size_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_filter_size_c2 = Integer(low=1,high=6,name = 'filter_size_c2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_filter_size_c3 = Integer(low=1,high=6,name = 'filter_size_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'embedding_matrix_fast_text',\n",
    "para_em_c1 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_em_c2 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_em_c3 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_em_trainable_flag = Categorical(categories=[True,False],name='em_trainable_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_free_em_dim = Categorical(categories=[100,300,400],name='free_em_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_batch_size = Categorical(categories=[50,100,150],name='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_epoch = Categorical(categories=[10,50,100,200,300,400,500],name='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size_c1,para_filter_size_c2,para_filter_size_c3,para_em_c1,para_em_c2,para_em_c3,para_em_trainable_flag,para_free_em_dim,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = [1e-4,0.5,100,100,2,4,6,'embedding_matrix_word2vec','embedding_matrix_glove','free',False,100,50,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(length,vocab_size,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    if em_c1 == 'free':\n",
    "        embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "    else:\n",
    "        embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag)(inputs1)\n",
    "\n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "#     embedding2 = Embedding(vocab_size, 400, weights = [embedding_matrix_godin],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    if em_c2 == 'free':\n",
    "        embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "    else:\n",
    "        embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "#     embedding3 = Embedding(vocab_size, 400)(inputs3)\n",
    "    if em_c3 == 'free':\n",
    "        embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "    else:\n",
    "        embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(2, activation='softmax')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # summarize\n",
    "#     print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dict to store performance of all models\n",
    "record = dict()\n",
    "key=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=parameters)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,em_trainable_flag,free_em_dim,batch_size,epoch):\n",
    "# n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate ==>',learning_rate)\n",
    "    print('dropout==>',dropout)\n",
    "    print('n_dense==>',n_dense)\n",
    "    print('n_filters==>',n_filters)\n",
    "    print('filter_size_c1',filter_size_c1)\n",
    "    print('filter_size_c2',filter_size_c2)\n",
    "    print('filter_size_c3',filter_size_c3)\n",
    "    print('em_c1==>',em_c1)\n",
    "    print('em_c2==>',em_c2)\n",
    "    print('em_c3==>',em_c3)\n",
    "    print('em_trainable_flag ==>',em_trainable_flag)\n",
    "    print('free_em_dim==>',free_em_dim)\n",
    "    print('batch_size==>',batch_size)\n",
    "    print('epocs==>',epoch)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = define_model(length = max_length,\n",
    "                         vocab_size=vocab_size,\n",
    "                         n_dense=n_dense,\n",
    "                         dropout=dropout,\n",
    "                         learning_rate=learning_rate,\n",
    "                         n_filters=n_filters,\n",
    "                         filter_size_c1=filter_size_c1,\n",
    "                         filter_size_c2=filter_size_c2,\n",
    "                         filter_size_c3=filter_size_c3,\n",
    "                         em_c1=em_c1,\n",
    "                         em_c2=em_c2,\n",
    "                         em_c3=em_c3,\n",
    "                         free_em_dim=free_em_dim,\n",
    "                         em_trainable_flag=em_trainable_flag)\n",
    "\n",
    "    \n",
    "    # Use Keras to train the model.\n",
    "    history_object = model.fit([trainX,trainX,trainX], trainY,epochs=epoch, batch_size=batch_size,validation_data=([devX,devX,devX],devY))\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history_object.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    \n",
    "    global key\n",
    "    global record\n",
    "    record[key] = {'parameters':dimensions,'val_acc':accuracy}\n",
    "    \n",
    "    model.save('models/'+str(key)+'.h5')\n",
    "    \n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate ==> 0.0001\n",
      "dropout==> 0.5\n",
      "n_dense==> 100\n",
      "n_filters==> 100\n",
      "filter_size_c1 2\n",
      "filter_size_c2 4\n",
      "filter_size_c3 6\n",
      "em_c1==> embedding_matrix_word2vec\n",
      "em_c2==> embedding_matrix_glove\n",
      "em_c3==> free\n",
      "em_trainable_flag ==> False\n",
      "free_em_dim==> 100\n",
      "batch_size==> 50\n",
      "epocs==> 10\n",
      "Train on 1569013 samples, validate on 16010 samples\n",
      "Epoch 1/10\n",
      "   7150/1569013 [..............................] - ETA: 5:25:39 - loss: 0.6851 - acc: 0.5538"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-f28938caf0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-4c38aade0e32>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size_c1, filter_size_c2, filter_size_c3, em_c1, em_c2, em_c3, em_trainable_flag, free_em_dim, batch_size, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Use Keras to train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Get the classification accuracy on the validation-set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fitness() got an unexpected keyword argument 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-f5b44a4ceba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# User suggested points at which to evaluate the objective first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fitness() got an unexpected keyword argument 'learning_rate'"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=500,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sorted(zip(search_result.func_vals, search_result.x_iters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "# history_object = model.fit([trainX,trainX,trainX], trainY,epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(12,10))\n",
    "# plt.plot(history_object.history['acc'])\n",
    "# # plt.plot(history_object.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(12,10))\n",
    "# plt.plot(history_object.history['loss'])\n",
    "# # plt.plot(history_object.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "# encode data\n",
    "# trainX = encode_text(tokenizer, trainLines, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # evaluate model on training dataset\n",
    "# loss, acc = model.evaluate([trainX,trainX,trainX], trainY, verbose=0)\n",
    "# print('Train Accuracy: %f' % (acc*100))\n",
    " \n",
    "# # evaluate model on test dataset dataset\n",
    "# loss, acc = model.evaluate([testX,testX,testX], testY, verbose=0)\n",
    "# print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.predict([testX,testX,testX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_predicted_prob(data):\n",
    "#     return [list(x) for x in model.predict(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicted probabilities\n",
    "# train_predicted_prob = get_predicted_prob([trainX,trainX,trainX])\n",
    "# test_predicted_prob = get_predicted_prob([testX,testX,testX])\n",
    "# predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting lables\n",
    "#if prob>0.5 -->1 else 0\n",
    "# def get_predicted_lables(prob):\n",
    "#     predicted_lables = []\n",
    "#     for x in prob:\n",
    "#         if x>0.5:\n",
    "#             predicted_lables.append(1)\n",
    "#         else:\n",
    "#             predicted_lables.append(0)\n",
    "#     return predicted_lables\n",
    "# def get_predicted_lables(prob):\n",
    "#     predicted_lables = []\n",
    "#     for x in prob:\n",
    "#         if x[0]>x[1]:\n",
    "#             predicted_lables.append(0)\n",
    "#         else:\n",
    "#             predicted_lables.append(1)\n",
    "#     return predicted_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_predicted_lables = get_predicted_lables(train_predicted_prob)\n",
    "# test_predicted_lables = get_predicted_lables(test_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_predicted_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # def get_score_from_prob(prob):\n",
    "# #     m = interp1d([0,1],[-1,1])\n",
    "# #     return [float(m(x)) for x in prob]\n",
    "# def get_score_from_prob(prob):\n",
    "#     intensity_score = []\n",
    "#     for x in prob:\n",
    "#         if x[0]>x[1]:\n",
    "#             intensity_score.append(-1*x[0])\n",
    "#         else:\n",
    "#             intensity_score.append(x[1])\n",
    "#     return intensity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_predicted_score = get_score_from_prob(train_predicted_prob)\n",
    "# test_predicted_score = get_score_from_prob(test_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_rmse = sqrt(mean_squared_error(score_trainY, train_predicted_score))\n",
    "# test_rmse = sqrt(mean_squared_error(score_testY, test_predicted_score))\n",
    "# print(\"(train rmse,test rmse)==\"+str((train_rmse,test_rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# foo = [x for x in zip(score_testY,test_predicted_score)]\n",
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
