{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi channel CNN for sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation,digits\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import word2vecReader as godin_embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [5,5]\n",
    "plt.style.use('seaborn-notebook')\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from aspect_specific_prob import get_normalized_sentence_relation_vector\n",
    "from math import sqrt\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed = 7\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_data_from_file(filename):\n",
    "    print(\"loading file = \",filename)\n",
    "    with open(filename,'r') as f:\n",
    "        foo = json.load(f)\n",
    "    sentence_id =[]    \n",
    "    sentence = []\n",
    "    sentence_snippet = []\n",
    "    sentence_target = []\n",
    "    score = []\n",
    "    for key in foo.keys():\n",
    "        for info in foo[key]['info']:\n",
    "            sentence_snippet.append(eval(info['snippets'])[0])\n",
    "            score.append(float(info['sentiment_score']))\n",
    "            sentence_target.append(info['target'])\n",
    "            sentence_id.append(key)\n",
    "            sentence.append(foo[key]['sentence'])\n",
    "    return sentence_id,sentence,sentence_snippet,sentence_target,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file =  dataset/master.json\n"
     ]
    }
   ],
   "source": [
    "sentence_id,sentence,sentence_snippet,sentence_target,score = load_data_from_file('dataset/master.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 1171, 1171, 1171, 1171)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_id),len(sentence),len(sentence_snippet),len(sentence_target),len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(series,old_range,new_range):\n",
    "    m = interp1d(old_range,new_range)\n",
    "    return [float(m(x)) for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rescale(score,[-1,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    #remove multiple repeat non num-aplha char !!!!!!!!!-->!\n",
    "    sentence = re.sub(r'(\\W)\\1{2,}', r'\\1', sentence) \n",
    "#     print(sentence)\n",
    "    #removes alpha char repeating more than twice aaaa->aa\n",
    "    sentence = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', sentence)\n",
    "#     print(sentence)\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "#     print(sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "#     print(sentence)\n",
    "    #removing stock names to see if it helps\n",
    "#     sentence = re.sub(r\"(?:\\$|https?\\://)\\S+\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    sentence = sentence.replace(\"'s\",'')\n",
    "    sentence = sentence.replace(\"-\",' ')\n",
    "#     print(sentence)\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "#     print(tokens)\n",
    "    #     remove remaining tokens that are not alphabetic\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#no removing non alpha words to keep stock names($ZSL)\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "#     for w in stop_words:\n",
    "#         print(w)\n",
    "#     print(tokens)\n",
    "    # filter out short tokens\n",
    "#     tokens = [word for word in tokens if len(word) > 1]\n",
    "#     print(tokens)\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "#     print(tokens)\n",
    "    tokens = [w.translate(remove_digits) for w in tokens]\n",
    "    tokens = [w.strip() for w in tokens]\n",
    "    tokens = [w for w in tokens if w!=\"\"]\n",
    "#     print(tokens)\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data set\n"
     ]
    }
   ],
   "source": [
    "# extract sentences out of df and cleaning it\n",
    "print('cleaning data set')\n",
    "sentence = [clean_sentence(x) for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning targets\n"
     ]
    }
   ],
   "source": [
    "print('cleaning targets')\n",
    "sentence_target = [clean_sentence(x) for x in sentence_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_sentence(\"Notable gainers among liquid option names this morning include $STX (+7.0%), $NEM (+4.6%), $WDC (+4.2%), $X (+4.1%), and $GME (+3.4%),\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = np.asarray(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(s.split()) for s in sentence]\n",
    "max_length = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02712614, 0.06329432, 0.15371477, 0.1049882 , 0.12457929,\n",
       "        0.04370322, 0.02210278, 0.02963782, 0.0140654 , 0.00502336]),\n",
       " array([ 2. ,  3.7,  5.4,  7.1,  8.8, 10.5, 12.2, 13.9, 15.6, 17.3, 19. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAJGCAYAAAByaLLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAz4/0ctbqiBiiNRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfd4137e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "plt.hist(lengths, normed=True,edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_print(s,target):\n",
    "    global count\n",
    "    count+=1\n",
    "    if count%10==0:\n",
    "        print(count)\n",
    "#     print(s)\n",
    "    return get_normalized_sentence_relation_vector(s,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sentence_enchance_prob = [progress_print(x,[y]) for x,y in zip(sentence,sentence_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_enchance_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model,sentence,godin_flag = False):\n",
    "    tokens = sentence.split()[:max_length]\n",
    "    if godin_flag:\n",
    "        embedding_matrix = np.zeros((max_length,400))\n",
    "    else:\n",
    "        embedding_matrix = np.zeros((max_length,300))\n",
    "    for i,word in enumerate(tokens):\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulding word2vec matrix of data set\n",
      "bulding godin matrix of data set\n"
     ]
    }
   ],
   "source": [
    "print(\"bulding word2vec matrix of data set\")\n",
    "data_word2vec = np.asarray([get_embedding_matrix(word2vec_model,x) for x in dataX])\n",
    "print(\"bulding godin matrix of data set\")\n",
    "data_godin = np.asarray([get_embedding_matrix(godin_model,x,godin_flag=True) for x in dataX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=2, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sk_mse(y_true,y_pred):\n",
    "     return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(length,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3):\n",
    "    # channel 1\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs1 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs1 = Input(shape=(length,400))\n",
    "#     if em_c1 == 'free':\n",
    "#         embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "#     else:\n",
    "#         embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag)(inputs1)\n",
    "\n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    if em_c2 == 'embedding_matrix_word2vec':\n",
    "        inputs2 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs2 = Input(shape=(length,400))\n",
    "#     embedding2 = Embedding(vocab_size, 400, weights = [embedding_matrix_godin],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "#     if em_c2 == 'free':\n",
    "#         embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "#     else:\n",
    "#         embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(inputs2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    if em_c1 == 'embedding_matrix_word2vec':\n",
    "        inputs3 = Input(shape=(length,300))\n",
    "    else:\n",
    "        inputs3 = Input(shape=(length,400))\n",
    "#     embedding3 = Embedding(vocab_size, 400)(inputs3)\n",
    "#     if em_c3 == 'free':\n",
    "#         embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "#     else:\n",
    "#         embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(inputs3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[sk_mse])\n",
    "    # summarize\n",
    "#     print(model.summary())\n",
    "#     plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dropout = Real(low=0.4, high=0.9,name = 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_n_filters = Categorical(categories=[100,200,300,400],name='n_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_filter_size_c1 = Integer(low=1,high=6,name = 'filter_size_c1')\n",
    "para_filter_size_c2 = Integer(low=1,high=6,name = 'filter_size_c2')\n",
    "para_filter_size_c3 = Integer(low=1,high=6,name = 'filter_size_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_em_c1 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c1')\n",
    "para_em_c2 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c2')\n",
    "para_em_c3 = Categorical(categories=['embedding_matrix_godin','embedding_matrix_word2vec'],name='em_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_epoch = Categorical(categories=[10,20,30,50],name='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size_c1,para_filter_size_c2,para_filter_size_c3,para_em_c1,para_em_c2,para_em_c3,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_parameters = [0.0006973763486468701,0.9,400,300,1,1,1,'embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_godin',8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = dict()\n",
    "key=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=parameters)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch):\n",
    "# n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag\n",
    "    # Print the hyper-parameters.\n",
    "    global key\n",
    "    global record\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    print('learning rate ==>',learning_rate)\n",
    "    print('dropout==>',dropout)\n",
    "    print('n_dense==>',n_dense)\n",
    "    print('n_filters==>',n_filters)\n",
    "    print('filter_size_c1',filter_size_c1)\n",
    "    print('filter_size_c2',filter_size_c2)\n",
    "    print('filter_size_c3',filter_size_c3)\n",
    "    print('em_c1==>',em_c1)\n",
    "    print('em_c2==>',em_c2)\n",
    "    print('em_c3==>',em_c3)\n",
    "    print('batch_size==>',batch_size)\n",
    "    print('epocs==>',epoch)\n",
    "\n",
    "    \n",
    "    cv_mse=[]\n",
    "    cv_r2=[]\n",
    "    for train,test in kfold.split(dataX,dataY):\n",
    "        model = define_model(length = max_length,\n",
    "                             n_dense=n_dense,\n",
    "                             dropout=dropout,\n",
    "                             learning_rate=learning_rate,\n",
    "                             n_filters=n_filters,\n",
    "                             filter_size_c1=int(filter_size_c1),\n",
    "                             filter_size_c2=int(filter_size_c2),\n",
    "                             filter_size_c3=int(filter_size_c3),\n",
    "                             em_c1=em_c1,\n",
    "                             em_c2=em_c2,\n",
    "                             em_c3=em_c3)\n",
    "        \n",
    "        input_array_train = [data_word2vec[train] if x=='embedding_matrix_word2vec' else data_godin[train] for x in [em_c1,em_c2,em_c3]]\n",
    "        input_array_test = [data_word2vec[test] if x=='embedding_matrix_word2vec' else data_godin[test] for x in [em_c1,em_c2,em_c3]]\n",
    "        \n",
    "        trainY = dataY[train]\n",
    "        testY = dataY[test]\n",
    "        \n",
    "        history_object = model.fit(input_array_train,trainY,epochs=epoch, batch_size=batch_size)\n",
    "        pred = model.predict(input_array_test)\n",
    "        pred_val = [x[0] for x in pred]\n",
    "        pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "        testY = rescale(testY,[0,1],[-1,1])\n",
    "        m = mean_squared_error(testY,pred_val)\n",
    "        r2 = r2_score(testY,pred_val)\n",
    "        print(m,r2)\n",
    "        cv_mse.append(m)\n",
    "        cv_r2.append(r2)\n",
    "    mse_mean = np.mean(cv_mse)\n",
    "    r2_mean = np.mean(cv_r2)\n",
    "    print(cv_mse)\n",
    "    print(cv_r2)\n",
    "    print(mse_mean)\n",
    "    print(r2_mean)\n",
    "    \n",
    "    record[key] = {'parameters':[learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,batch_size,epoch],'mse_mean':mse_mean,'r2_mean':r2_mean,'cv_mse':cv_mse,'cv_r2':cv_r2}\n",
    "        \n",
    "    with open('models/record.json', 'w') as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    \n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -mse_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=1------------------\n",
      "learning rate ==> 0.0006973763486468701\n",
      "dropout==> 0.9\n",
      "n_dense==> 400\n",
      "n_filters==> 300\n",
      "filter_size_c1 6\n",
      "filter_size_c2 2\n",
      "filter_size_c3 4\n",
      "em_c1==> embedding_matrix_godin\n",
      "em_c2==> embedding_matrix_word2vec\n",
      "em_c3==> embedding_matrix_godin\n",
      "batch_size==> 8\n",
      "epocs==> 10\n",
      "Epoch 1/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.7015 - sk_mse: 0.0471\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6877 - sk_mse: 0.0406\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6742 - sk_mse: 0.0344\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6644 - sk_mse: 0.0296\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6602 - sk_mse: 0.0274\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6547 - sk_mse: 0.0247\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6475 - sk_mse: 0.0213\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6473 - sk_mse: 0.0213\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6416 - sk_mse: 0.0185\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 5s 8ms/step - loss: 0.6390 - sk_mse: 0.0174\n",
      "0.14132236347591814 0.09586239315212086\n",
      "Epoch 1/10\n",
      "586/586 [==============================] - 5s 9ms/step - loss: 0.6994 - sk_mse: 0.0452\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6817 - sk_mse: 0.0373\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6708 - sk_mse: 0.0320\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6678 - sk_mse: 0.0304: 0s - loss:\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6575 - sk_mse: 0.0256\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6526 - sk_mse: 0.0231\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 5s 9ms/step - loss: 0.6460 - sk_mse: 0.0200\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6451 - sk_mse: 0.0194\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6390 - sk_mse: 0.0164\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 5s 8ms/step - loss: 0.6386 - sk_mse: 0.0166\n",
      "0.13792750767274037 0.14872495920935613\n",
      "[0.14132236347591814, 0.13792750767274037]\n",
      "[0.09586239315212086, 0.14872495920935613]\n",
      "0.13962493557432926\n",
      "0.1222936761807385\n",
      "-----------------------------combination no=2------------------\n",
      "learning rate ==> 0.0033518465729761387\n",
      "dropout==> 0.6318539798339841\n",
      "n_dense==> 100\n",
      "n_filters==> 100\n",
      "filter_size_c1 5\n",
      "filter_size_c2 5\n",
      "filter_size_c3 3\n",
      "em_c1==> embedding_matrix_godin\n",
      "em_c2==> embedding_matrix_word2vec\n",
      "em_c3==> embedding_matrix_godin\n",
      "batch_size==> 64\n",
      "epocs==> 10\n",
      "Epoch 1/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6928 - sk_mse: 0.0435\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6693 - sk_mse: 0.0321\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6508 - sk_mse: 0.0229\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6360 - sk_mse: 0.0160\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6293 - sk_mse: 0.0129\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6232 - sk_mse: 0.0095\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6213 - sk_mse: 0.0090\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6160 - sk_mse: 0.0065\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6166 - sk_mse: 0.0068\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 1s 1ms/step - loss: 0.6164 - sk_mse: 0.0067\n",
      "0.1315736062551857 0.15823198425223006\n",
      "Epoch 1/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6982 - sk_mse: 0.0449\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6758 - sk_mse: 0.0346\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.6577 - sk_mse: 0.0259\n",
      "Epoch 4/10\n",
      "128/586 [=====>........................] - ETA: 0s - loss: 0.6364 - sk_mse: 0.0152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f5b44a4ceba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-5565f2167c9c>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size_c1, filter_size_c2, filter_size_c3, em_c1, em_c2, em_c3, batch_size, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"traning done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10343218728427603 0.3093617125885538\n",
      "0.11082901716092575 0.3214193870990977\n",
      "0.10922397337212918 0.2996706946188652\n",
      "0.12080560219923858 0.27274889295718263\n",
      "0.10764737821782466 0.3265275466674228\n"
     ]
    }
   ],
   "source": [
    "# for train,test in kfold.split(dataX,dataY):\n",
    "#     model = define_model(length = max_length,\n",
    "#                          n_dense=400,\n",
    "#                          dropout=0.9,\n",
    "#                          learning_rate=0.0006973763486468701,\n",
    "#                          n_filters=300,\n",
    "#                          filter_size_c1=1,\n",
    "#                          filter_size_c2=1,\n",
    "#                          filter_size_c3=1,\n",
    "#                          em_c1='embedding_matrix_godin',\n",
    "#                          em_c2='embedding_matrix_word2vec',\n",
    "#                          em_c3='embedding_matrix_godin')\n",
    "#     input_array_train = [data_godin[train],data_word2vec[train],data_godin[train]]\n",
    "#     input_array_test = [data_godin[test],data_word2vec[test],data_godin[test]]\n",
    "#     trainY = dataY[train]\n",
    "#     testY = dataY[test]\n",
    "#     history_object = model.fit(input_array_train,trainY,epochs=30, batch_size=8,verbose=0)\n",
    "#     pred = model.predict(input_array_test)\n",
    "#     pred_val = [x[0] for x in pred]\n",
    "#     pred_val = rescale(pred_val,[0,1],[-1,1])\n",
    "#     testY = rescale(testY,[0,1],[-1,1])\n",
    "#     m = mean_squared_error(testY,pred_val)\n",
    "#     r2 = r2_score(testY,pred_val)\n",
    "#     print(m,r2)\n",
    "#     cv_mse.append(m)\n",
    "#     cv_r2.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_mse), np.std(cv_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"%.5f (+/- %.5f)\" % (np.mean(cv_r2), np.std(cv_r2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_array_train = [train_godin,train_word2vec,train_godin]\n",
    "# input_array_test = [test_godin,test_word2vec,test_godin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history_object = model.fit(input_array_train, trainY,epochs=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(input_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_val = [x[0] for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_val = rescale(pred_val)\n",
    "# testY = rescale(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(testY,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r2_score(testY,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i,y in zip(pred_val,testY):\n",
    "#     print(i,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
